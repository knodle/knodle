{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook demonstrates how negation and uncertainty patterns can be created for the CheXpert labeler. This is illustrated using a small set of sample data on weather forecasts. The text data was created using weather forecast transcripts which can be found [here](https://learnenglishteens.britishcouncil.org/sites/teens/files/weather_forecast_-_transcript_4.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, the data has to be loaded from a Knodle dataset collection. The data consists of \"phrases\", which include mentions and unmentions of eight different weather labels, and \"patterns\", which are divided into pre-negation uncertainty, negation and post-negation uncertainty patterns.\n",
    "While the mentions are used as main rules for the corresponding labels and represented in the T and Z matrices, the unmentions and the patterns are used to finetune the matches. The unmentions, like the mentions, are saved in plain text files consisting of simple keywords corresponding to the respective labels. The patterns are saved in three different text files comprised of [SemgrexPatterns](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html) which are patterns for matching node and edge configurations of a dependency graph. The patterns are composed of nodes, which represent IndexedWords, and the relations between them, which represent edges in a SemanticGraph. For more detailed information, please have a look at the syntax [here](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'negbio'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_286686/233097017.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mminio\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMinio\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mknodle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabeler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCheXpert\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabel\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLabeler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;31m# Client to access the dataset collection\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/knodle/knodle/labeler/CheXpert/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mknodle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabeler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCheXpert\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/knodle/knodle/labeler/CheXpert/stages/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mt_matrix_fct\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mz_matrix_fct\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_rule_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mextract\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mExtractor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mclassify\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mClassifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0maggregate\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAggregator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/knodle/knodle/labeler/CheXpert/stages/load.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\"\"\"Define report loader class.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mnegbio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpipeline\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtext2bioc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mssplit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'negbio'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from minio import Minio\n",
    "from knodle.labeler.CheXpert.label import Labeler\n",
    "\n",
    "# Client to access the dataset collection\n",
    "client = Minio(\"knodle.cc\", secure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Specify the path to the directory where you want all files to be saved to as `CHEXPERT_DATA_DIR`. The default path is given below, simply adjust it if you wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DATA DIRECTORY -------------------------------------------------------------------------------------\n",
    "CHEXPERT_DATA_DIR = os.path.join(os.getcwd(), \"examples\", \"labeler\", \"chexpert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is downloading the data from Minio. In the next section of code, the `mention`, `unmention` & `pattern` directories are first created and then the text files are saved to them. In case you want to download other data, just change the path to the correct Minio folder and adjust the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RULE DIRECTORIES -----------------------------------------------------------------------------------\n",
    "MENTION_DATA_DIR = os.path.join(CHEXPERT_DATA_DIR, \"phrases\", \"mention\")\n",
    "os.makedirs(MENTION_DATA_DIR, exist_ok=True)\n",
    "files_mention = [\n",
    "    \"clouds.txt\", \"cold.txt\", \"rain.txt\", \"snow.txt\",\n",
    "    \"storm.txt\", \"sun.txt\", \"warm.txt\", \"wind.txt\"\n",
    "]\n",
    "for file in tqdm(files_mention):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/phrases/mention/\", file),\n",
    "        file_path=os.path.join(MENTION_DATA_DIR, file),\n",
    "    )\n",
    "\n",
    "UNMENTION_DATA_DIR = os.path.join(CHEXPERT_DATA_DIR, \"phrases\", \"unmention\")\n",
    "os.makedirs(UNMENTION_DATA_DIR, exist_ok=True)\n",
    "files_unmention = [\n",
    "    \"rain.txt\"\n",
    "]\n",
    "for file in tqdm(files_unmention):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/phrases/unmention/\", file),\n",
    "        file_path=os.path.join(UNMENTION_DATA_DIR, file),\n",
    "    )\n",
    "\n",
    "\n",
    "# PATTERN DIRECTORY ----------------------------------------------------------------------------------\n",
    "PATTERNS_DIR = os.path.join(CHEXPERT_DATA_DIR, \"patterns\")\n",
    "os.makedirs(PATTERNS_DIR, exist_ok=True)\n",
    "files_patterns = [\n",
    "    \"pre_negation_uncertainty.txt\", \"negation.txt\", \"post_negation_uncertainty.txt\"\n",
    "]\n",
    "for file in tqdm(files_patterns):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/patterns/\", file),\n",
    "        file_path=os.path.join(PATTERNS_DIR, file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Following the same steps as above, the sample data, for which we use weather forecasts, is downloaded and stored. The sample data, in contrast to the other files, needs to be provided in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SAMPLE DIRECTORY -----------------------------------------------------------------------------------\n",
    "SAMPLE_DIR = os.path.join(CHEXPERT_DATA_DIR, \"reports\")\n",
    "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
    "files_sample = [\n",
    "    \"weather_forecast.csv\"\n",
    "]\n",
    "for file in tqdm(files_sample):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/reports/\", file),\n",
    "        file_path=os.path.join(SAMPLE_DIR, file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the directory where you want the output matrices X, T and Z to be stored, needs to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# OUTPUT DIRECTORY -----------------------------------------------------------------------------------\n",
    "OUTPUT_DIR = os.path.join(CHEXPERT_DATA_DIR, \"output\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preview Dataset & Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The sample data, or X matrix as it is called within Knodle, is shown below. It consists of four documents, each including information about the weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(SAMPLE_DIR, \"weather_forecast.csv\"), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below, the post-negation uncertainty patterns are shown for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(PATTERNS_DIR, \"post_negation_uncertainty.txt\"), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, that the data is loaded, use the adjusted [CheXpert labeler](https://github.com/stanfordmlgroup/chexpert-labeler) in Knodle to label the weather forecasts. The labeler is started by initiating the `Labeler()` class, followed by running the associated `label()` function. Since we are not using the original CheXpert data, `chexpert_bool` is set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The labeler class is initiated without passing a config.py file, so the default one is used.\n",
    "labeler = Labeler()\n",
    "\n",
    "# The label function is run, outputting the matrices X, T and Z.\n",
    "labeler.label(transform_patterns=False, uncertain=-1, chexpert_bool=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately the code cannot be run from this notebook, but must be run in a python file from the terminal, because of NegBio. Please run these lines of code in your terminal:\n",
    "\n",
    "**0) Go to home directory**\n",
    "`cd`\n",
    "\n",
    "**1) Clone the repository**\n",
    "`git clone https://github.com/ncbi-nlp/NegBio.git`\n",
    "\n",
    "**2) Add the NegBio directory to your PYTHONPATH**\n",
    "`export PYTHONPATH=\"${PYTHONPATH}:/home/elisabear/NegBio\"`\n",
    "\n",
    "**3) Create the virtual environment**\n",
    "`cd ~/PycharmProjects/knodle/knodle/labeler/CheXpert\n",
    "conda env create -f environment.yml`\n",
    "\n",
    "**4) Activate the virtual environment**\n",
    "`conda activate chexpert-label`\n",
    "\n",
    "**5) Install NLTK data**\n",
    "`python -m nltk.downloader universal_tagset punkt wordnet`\n",
    "\n",
    "**6) Run label.py**\n",
    "`cd ~/PycharmProjects/knodle`\n",
    "`jupyter nbconvert --to python examples/labeler/chexpert/chexpert_patterns_tutorial.ipynb`\n",
    "`python examples/labeler/chexpert/chexpert_patterns_tutorial.py`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}