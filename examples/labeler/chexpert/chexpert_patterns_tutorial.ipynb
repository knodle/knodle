{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook demonstrates how negation and uncertainty patterns can be created for the CheXpert labeler. This is illustrated using a small set of sample data on weather forecasts. The text data was created using weather forecast transcripts which can be found [here](https://learnenglishteens.britishcouncil.org/sites/teens/files/weather_forecast_-_transcript_4.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, the data has to be loaded from a Knodle dataset collection. The data consists of \"phrases\", which include mentions and unmentions of eight different weather labels, and \"patterns\", which are divided into pre-negation uncertainty, negation and post-negation uncertainty patterns.\n",
    "While the mentions are used as main rules for the corresponding labels and represented in the T and Z matrices, the unmentions and the patterns are used to finetune the matches. The unmentions, like the mentions, are saved in plain text files consisting of simple keywords corresponding to the respective labels. The patterns are saved in three different text files comprised of [SemgrexPatterns](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html) which are patterns for matching node and edge configurations of a dependency graph. The patterns are composed of nodes, which represent IndexedWords, and the relations between them, which represent edges in a SemanticGraph. For more detailed information, please have a look at the syntax [here](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'negbio'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_286686/233097017.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mminio\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMinio\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mknodle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabeler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCheXpert\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabel\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLabeler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;31m# Client to access the dataset collection\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/knodle/knodle/labeler/CheXpert/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mknodle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabeler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCheXpert\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/knodle/knodle/labeler/CheXpert/stages/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mt_matrix_fct\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mz_matrix_fct\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_rule_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mextract\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mExtractor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mclassify\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mClassifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0maggregate\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAggregator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/knodle/knodle/labeler/CheXpert/stages/load.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\"\"\"Define report loader class.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mnegbio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpipeline\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtext2bioc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mssplit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'negbio'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from minio import Minio\n",
    "from knodle.labeler.CheXpert.label import Labeler\n",
    "\n",
    "# Client to access the dataset collection\n",
    "client = Minio(\"knodle.cc\", secure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Specify the path to the directory where you want all files to be saved to as `CHEXPERT_DATA_DIR`. The default path is given below, simply adjust it if you wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DATA DIRECTORY -------------------------------------------------------------------------------------\n",
    "CHEXPERT_DATA_DIR = os.path.join(os.getcwd(), \"examples\", \"labeler\", \"chexpert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is downloading the data from Minio. In the next section of code, the `mention`, `unmention` & `pattern` directories are first created and then the text files are saved to them. In case you want to download other data, just change the path to the correct Minio folder and adjust the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc67d6d68a8644918b3c3d5db9d8f221"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 22:14:40,188 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/clouds.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/clouds.txt\n",
      "2022-01-23 22:14:40,274 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/clouds.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/clouds.txt\n",
      "2022-01-23 22:14:40,300 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/cold.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/cold.txt\n",
      "2022-01-23 22:14:40,320 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/cold.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/cold.txt\n",
      "2022-01-23 22:14:40,342 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/rain.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/rain.txt\n",
      "2022-01-23 22:14:40,360 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/rain.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/rain.txt\n",
      "2022-01-23 22:14:40,388 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/snow.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/snow.txt\n",
      "2022-01-23 22:14:40,406 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/snow.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/snow.txt\n",
      "2022-01-23 22:14:40,434 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/storm.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/storm.txt\n",
      "2022-01-23 22:14:40,452 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/storm.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/storm.txt\n",
      "2022-01-23 22:14:40,471 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/sun.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/sun.txt\n",
      "2022-01-23 22:14:40,488 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/sun.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/sun.txt\n",
      "2022-01-23 22:14:40,506 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/warm.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/warm.txt\n",
      "2022-01-23 22:14:40,524 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/warm.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/warm.txt\n",
      "2022-01-23 22:14:40,543 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/wind.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/wind.txt\n",
      "2022-01-23 22:14:40,562 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/mention/wind.txt -> https://knodle.cc/knodle/datasets/weather/phrases/mention/wind.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90d4542b95e84558856a88ad6387069b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 22:14:40,598 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/unmention/rain.txt -> https://knodle.cc/knodle/datasets/weather/phrases/unmention/rain.txt\n",
      "2022-01-23 22:14:40,615 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/phrases/unmention/rain.txt -> https://knodle.cc/knodle/datasets/weather/phrases/unmention/rain.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9174e779a78d42c7993ed2e069218107"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 22:14:40,648 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/patterns/pre_negation_uncertainty.txt -> https://knodle.cc/knodle/datasets/weather/patterns/pre_negation_uncertainty.txt\n",
      "2022-01-23 22:14:40,667 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/patterns/pre_negation_uncertainty.txt -> https://knodle.cc/knodle/datasets/weather/patterns/pre_negation_uncertainty.txt\n",
      "2022-01-23 22:14:40,686 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/patterns/negation.txt -> https://knodle.cc/knodle/datasets/weather/patterns/negation.txt\n",
      "2022-01-23 22:14:40,704 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/patterns/negation.txt -> https://knodle.cc/knodle/datasets/weather/patterns/negation.txt\n",
      "2022-01-23 22:14:40,726 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/patterns/post_negation_uncertainty.txt -> https://knodle.cc/knodle/datasets/weather/patterns/post_negation_uncertainty.txt\n",
      "2022-01-23 22:14:40,745 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/patterns/post_negation_uncertainty.txt -> https://knodle.cc/knodle/datasets/weather/patterns/post_negation_uncertainty.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RULE DIRECTORIES -----------------------------------------------------------------------------------\n",
    "MENTION_DATA_DIR = os.path.join(CHEXPERT_DATA_DIR, \"phrases\", \"mention\")\n",
    "os.makedirs(MENTION_DATA_DIR, exist_ok=True)\n",
    "files_mention = [\n",
    "    \"clouds.txt\", \"cold.txt\", \"rain.txt\", \"snow.txt\",\n",
    "    \"storm.txt\", \"sun.txt\", \"warm.txt\", \"wind.txt\"\n",
    "]\n",
    "for file in tqdm(files_mention):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/phrases/mention/\", file),\n",
    "        file_path=os.path.join(MENTION_DATA_DIR, file),\n",
    "    )\n",
    "\n",
    "UNMENTION_DATA_DIR = os.path.join(CHEXPERT_DATA_DIR, \"phrases\", \"unmention\")\n",
    "os.makedirs(UNMENTION_DATA_DIR, exist_ok=True)\n",
    "files_unmention = [\n",
    "    \"rain.txt\"\n",
    "]\n",
    "for file in tqdm(files_unmention):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/phrases/unmention/\", file),\n",
    "        file_path=os.path.join(UNMENTION_DATA_DIR, file),\n",
    "    )\n",
    "\n",
    "\n",
    "# PATTERN DIRECTORY ----------------------------------------------------------------------------------\n",
    "PATTERNS_DIR = os.path.join(CHEXPERT_DATA_DIR, \"patterns\")\n",
    "os.makedirs(PATTERNS_DIR, exist_ok=True)\n",
    "files_patterns = [\n",
    "    \"pre_negation_uncertainty.txt\", \"negation.txt\", \"post_negation_uncertainty.txt\"\n",
    "]\n",
    "for file in tqdm(files_patterns):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/patterns/\", file),\n",
    "        file_path=os.path.join(PATTERNS_DIR, file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Following the same steps as above, the sample data, for which we use weather forecasts, is downloaded and stored. The sample data, in contrast to the other files, needs to be provided in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b40e20dbec74d5fbd3df799684aada4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 22:14:40,785 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/reports/weather_forecast.csv -> https://knodle.cc/knodle/datasets/weather/reports/weather_forecast.csv\n",
      "2022-01-23 22:14:40,811 urllib3.poolmanager INFO     Redirecting http://knodle.cc/knodle/datasets/weather/reports/weather_forecast.csv -> https://knodle.cc/knodle/datasets/weather/reports/weather_forecast.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE DIRECTORY -----------------------------------------------------------------------------------\n",
    "SAMPLE_DIR = os.path.join(CHEXPERT_DATA_DIR, \"reports\")\n",
    "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
    "files_sample = [\n",
    "    \"weather_forecast.csv\"\n",
    "]\n",
    "for file in tqdm(files_sample):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/weather/reports/\", file),\n",
    "        file_path=os.path.join(SAMPLE_DIR, file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the directory where you want the output matrices X, T and Z to be stored, needs to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# OUTPUT DIRECTORY -----------------------------------------------------------------------------------\n",
    "OUTPUT_DIR = os.path.join(CHEXPERT_DATA_DIR, \"output\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preview Dataset & Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The sample data, or X matrix as it is called within Knodle, is shown below. It consists of four documents, each including information about the weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   0\n0  It is very windy and cold. There is going to b...\n1  It is rainy all day. There may be a thundersto...\n2  The weather is dry, but cloudy. So no rain today.\n3          It is cold, but snow is still not likely.\n4  The weather is acting up today, even a storm i...\n5  The weather is getting better, no development ...\n6  The clouds have cleared, it is going to be a s...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It is very windy and cold. There is going to b...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It is rainy all day. There may be a thundersto...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The weather is dry, but cloudy. So no rain today.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It is cold, but snow is still not likely.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The weather is acting up today, even a storm i...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The weather is getting better, no development ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The clouds have cleared, it is going to be a s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(SAMPLE_DIR, \"weather_forecast.csv\"), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below, the post-negation uncertainty patterns are shown for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    0\n0                          # Rain cannot be excluded.\n1   {} < {} ({lemma:/excluded/} > {dependency:/neg...\n2                      # May/might/would/could be XXX\n3             {} > {} {lemma:/may|might|would|could/}\n4   # '{} >{dependency:/cop/} {lemma:/may|would|co...\n5                         # A Storm would be possible\n6                           {} <{} {lemma:/possible/}\n7                                        # may be XXX\n8   {} <{} {lemma:/be/} >{} {lemma:/may|could|would/}\n9                                        # XXX or YYY\n10                     {} > {dependency:/conj:or/} {}\n11                     {} < {dependency:/conj:or/} {}",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td># Rain cannot be excluded.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{} &lt; {} ({lemma:/excluded/} &gt; {dependency:/neg...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td># May/might/would/could be XXX</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{} &gt; {} {lemma:/may|might|would|could/}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td># '{} &gt;{dependency:/cop/} {lemma:/may|would|co...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td># A Storm would be possible</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{} &lt;{} {lemma:/possible/}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td># may be XXX</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{} &lt;{} {lemma:/be/} &gt;{} {lemma:/may|could|would/}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td># XXX or YYY</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>{} &gt; {dependency:/conj:or/} {}</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>{} &lt; {dependency:/conj:or/} {}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(PATTERNS_DIR, \"post_negation_uncertainty.txt\"), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, that the data is loaded, use the adjusted [CheXpert labeler](https://github.com/stanfordmlgroup/chexpert-labeler) in Knodle to label the weather forecasts. The labeler is started by initiating the `Labeler()` class, followed by running the associated `label()` function. Since we are not using the original CheXpert data, `chexpert_bool` is set to `False`. And the `config_pattern_tutorial.py` file is specified as config file for the labeler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Labeler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_286686/3443327070.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# The labeler class is initiated without passing a config.py file, so the default one is used.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mlabeler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLabeler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# The label function is run, outputting the matrices X, T and Z.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mlabeler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtransform_patterns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muncertain\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchexpert_bool\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Labeler' is not defined"
     ]
    }
   ],
   "source": [
    "# The labeler class is initiated without passing a config.py file, so the default one is used.\n",
    "labeler = Labeler()\n",
    "\n",
    "# The label function is run, outputting the matrices X, T and Z.\n",
    "labeler.label(transform_patterns=False, uncertain=-1, chexpert_bool=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately the code cannot be run from this notebook, but must be run in a python file from the terminal, because of NegBio. Please run these lines of code in your terminal:\n",
    "\n",
    "**0) Go to home directory**\n",
    "`cd`\n",
    "\n",
    "**1) Clone the repository**\n",
    "`git clone https://github.com/ncbi-nlp/NegBio.git`\n",
    "\n",
    "**2) Add the NegBio directory to your PYTHONPATH**\n",
    "`export PYTHONPATH=\"${PYTHONPATH}:/home/elisabear/NegBio\"`\n",
    "\n",
    "**3) Create the virtual environment**\n",
    "`cd ~/PycharmProjects/knodle/knodle/labeler/CheXpert\n",
    "conda env create -f environment.yml`\n",
    "\n",
    "**4) Activate the virtual environment**\n",
    "`conda activate chexpert-label`\n",
    "\n",
    "**5) Install NLTK data**\n",
    "`python -m nltk.downloader universal_tagset punkt wordnet`\n",
    "\n",
    "**6) Run label.py**\n",
    "`cd ~/PycharmProjects/knodle`\n",
    "`jupyter nbconvert --to python examples/labeler/chexpert/chexpert_patterns_tutorial.ipynb`\n",
    "`python examples/labeler/chexpert/chexpert_patterns_tutorial.py`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}