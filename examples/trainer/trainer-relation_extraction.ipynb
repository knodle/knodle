{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e3943f",
   "metadata": {},
   "source": [
    "# Simple knodle trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071bc776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 16:02:00,380 root         INFO     Initalized logger\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import joblib \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch   \n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertTokenizerFast, AdamW, BertConfig, BertForSequenceClassification, AutoModel, BertModel, BertConfig, AutoConfig\n",
    "from knodle.trainer import AutoTrainer, AutoConfig, baseline, MajorityVoteTrainer, multi_trainer\n",
    "#from knodle.trainer.baseline.config import MajorityConfig\n",
    "from config import MajorityConfig\n",
    "from knodle.transformation.majority import input_to_majority_vote_input\n",
    "from knodle.transformation.torch_input import input_labels_to_tensordataset\n",
    "from knodle.trainer.trainer import BaseTrainer\n",
    "from knodle.transformation.filter import filter_probability_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a7f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "x_train = joblib.load('./train_embeddings_torch_540.joblib')\n",
    "z_train = joblib.load('./z_torch_matrix.joblib')\n",
    "z_train = np.array(z_train)\n",
    "#t_train = joblib.load('./t_torch_matrix.joblib')\n",
    "t_train = joblib.load('./t_matrix_v02.joblib')    # dim: 74 * 3\n",
    "t_train = np.array(t_train)\n",
    "x_test = joblib.load('./test_embeddings.joblib')\n",
    "y_test = joblib.load('./test_data_labels.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3996d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.type(torch.IntTensor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1821aba",
   "metadata": {},
   "source": [
    "Check the size of the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61cb0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([540, 768])\n",
      "(4627, 74)\n",
      "4627 74\n",
      "74 3\n",
      "torch.Size([195, 768])\n",
      "torch.Size([8411, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.size())\n",
    "print(z_train.shape)\n",
    "print(len(z_train), len(z_train[0]))\n",
    "#print(t_train.shape)\n",
    "print(len(t_train), len(t_train[0]))\n",
    "print(x_test.size())\n",
    "print(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9cd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = z_train[:540, :]\n",
    "#z_train = torch.stack(z_train, dim=0).numpy()\n",
    "y_test = y_test[:195, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706538dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert tensors to numpy\n",
    "#z_train_np = z_train.cpu().detach().numpy()\n",
    "###t_train_np = t_train.cpu().detach().numpy()\n",
    "#z_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912a620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = TensorDataset(x_train)\n",
    "x_test = TensorDataset(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6f9d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x240980dd1c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e95c3fd",
   "metadata": {},
   "source": [
    "Convert matrices to TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f024861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2e8557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 16:02:08,455 knodle.trainer.config INFO     The cache will be saved to C:\\Users\\stephanie\\Uni\\Data_Science_project\\Code\\cache folder\n",
      "2023-01-27 16:02:08,456 knodle.trainer.config INFO     The trained models will be saved to the C:\\Users\\stephanie\\Uni\\Data_Science_project\\Code\\cache directory.\n",
      "2023-01-27 16:02:08,462 knodle.trainer.config INFO     Model will be trained on cpu\n",
      "2023-01-27 16:02:08,489 knodle.transformation.rule_reduction INFO     No filtering criteria ('max_rule' or 'min_coverage' for rule specified, returning the original rule matches.\n",
      "C:\\Users\\stephanie\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "C:\\Users\\stephanie\\anaconda3\\envs\\ds_project\\lib\\site-packages\\knodle\\transformation\\majority.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rule_counts_probs = rule_counts / rule_counts.sum(axis=1).reshape(-1, 1)\n",
      "2023-01-27 16:02:08,528 knodle.trainer.trainer INFO     ======================================\n",
      "2023-01-27 16:02:08,529 knodle.trainer.trainer INFO     Training starts\n",
      "2023-01-27 16:02:08,530 knodle.trainer.trainer INFO     ======================================\n",
      "2023-01-27 16:02:08,537 knodle.trainer.trainer INFO     Epoch: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': None, 'caching_suffix': '', 'caching_folder': 'C:\\\\Users\\\\stephanie\\\\Uni\\\\Data_Science_project\\\\Code\\\\cache', 'saved_models_dir': 'C:\\\\Users\\\\stephanie\\\\Uni\\\\Data_Science_project\\\\Code\\\\cache', 'criterion': <function cross_entropy_with_probs at 0x0000024093FD43A8>, 'lr': 0.0001, 'batch_size': 2, 'output_classes': 3, 'grad_clipping': None, 'device': device(type='cpu'), 'epochs': 2, 'optimizer': <class 'transformers.optimization.AdamW'>, 'class_weights': tensor([1., 1., 1.]), 'filter_non_labelled': True, 'other_class_id': None, 'evaluate_with_other_class': False, 'ids2labels': None, 'max_rules': None, 'min_coverage': None, 'drop_rules': False, 'use_probabilistic_labels': False, 'probability_threshold': None}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9cff71ee874cc0859f57e539604e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [2, 768].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21200\\2479192946.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\knodle\\trainer\\baseline\\majority.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model_input_x, rule_matches_z, dev_model_input_x, dev_gold_labels_y)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mfeature_label_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_label_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_label_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\knodle\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_train_loop\u001b[1;34m(self, feature_label_dataloader, use_sample_weights, draw_plot)\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [2, 768].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "custom_model_config = MajorityConfig(\n",
    "    optimizer=AdamW,\n",
    "    lr=1e-4,\n",
    "    batch_size=2,\n",
    "    epochs=2,\n",
    "    filter_non_labelled=True,\n",
    "    output_classes = 3\n",
    ")\n",
    "\n",
    "print(custom_model_config.__dict__)\n",
    "\n",
    "trainer = MajorityVoteTrainer(\n",
    "    model=model,\n",
    "    mapping_rules_labels_t=t_train,\n",
    "    model_input_x=x_train,\n",
    "    rule_matches_z=z_train,\n",
    "    trainer_config=custom_model_config,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config-file:\n",
    "\n",
    "#from knodle.trainer.auto_config import AutoConfig\n",
    "#from knodle.trainer.config import BaseTrainerConfig\n",
    "\n",
    "\n",
    "#@AutoConfig.register(\"majority\")\n",
    "#class MajorityConfig(BaseTrainerConfig):\n",
    "#    def __init__(\n",
    "#            self,\n",
    "#            use_probabilistic_labels: bool = False,\n",
    "#            **kwargs\n",
    "#    ):\n",
    "#        super().__init__(**kwargs)\n",
    "#        self.use_probabilistic_labels = use_probabilistic_labels\n",
    "#        self.probability_threshold = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
