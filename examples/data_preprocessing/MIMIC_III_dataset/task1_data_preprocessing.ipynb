{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Disease Named Entity Recognition (D-NER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Contex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this project is to provide a pipeline for the input preprocessing for sequence tagging and named entity recognition for a medical domain project with Knodle. In other words, the tagging of categories of entities, here diseases, within text. For this we make use of the MIMIC III dataset and create weakly annotated labels with a lexicon look-up with keyword lists from relevante datasets. Those shall then be denoised within Knodle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction - Data and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, this project will utilize the Mimic III dataset as training data. For the development and evaluation of the model, the NCIT dataset will be used, for which the existing tags are as follows:\n",
    "DiseaseClass, SpecificDisease, Modfier and CompositeMention\n",
    "\n",
    "For the Class of CompositeDisease the occurence of a term of DiseaseClass or SpecificDisease followed by another seems like a viable solution, with an instance of and, or or / \\ between them. Given that the following preprocessing pipeline will only deal with unigrams and the class Mod is not used in the final model, the elements in use ne\n",
    "\n",
    "In order to supplement the Mimic III dataset for this task, three other datasets where consulted to aid in the fitting of specific categories for the matching with the structure of the classes:\n",
    "\n",
    "National Cancer Institute Thesaurus: NCI9d - Thesaurus.txt: NCI Thesaurus Version 22.09d - flattened from the owl format \n",
    "from their own webpage: https://evs.nci.nih.gov/evs-download/thesaurus-downloads\n",
    "\n",
    "The vast ULMS dataset (Unified Medical Language System),\n",
    "after authentification, to be accessed at: https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html\n",
    "Specifically the table NB.DB\n",
    "\n",
    "MEDIC - CTD's MEDIC disease vocabulary is a modified subset of descriptors from the “Diseases” [C] branch of the U.S. National Library of Medicine's Medical Subject Headings (MeSH®),combined with genetic disorders from the Online Mendelian Inheritance in Man® (OMIM®) database. Comparative Toxicogenomics Database: https://ctdbase.org/downloads/#alldiseases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access the MIMIC II dataset, a PhysioNet account and a completion of the necessary credentialing process are needed. This involves passing the \"Data or Specimens Only Research\" course from the \"Human Research\" curriculum offered by the Collaborative Institutional Training Initiative (CITI Program). This can entail some waiting time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC-III (\"Medical Information Mart for Intensive Care\") is a large, single-center database consisting of 26 tables, containing detailed information on patients admitted to critical care units at a large tertiary care hospital. Events such as notes, laboratory tests, and fluid balance are stored in a series of ‘events’ tables. The NOTEEVENTS table contains all clinical notes related to an event for a given patient, for the purposes of the training data, this will serve as text to be labeled, while D_ICD_DIAGNOSES, which carries the disease mentions will serve as the basis of two of the keyword lists for labeling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the scope and its potential for scaleable expansion: \n",
    "\n",
    "Modifier, CompositeMention classes will not be implemented in the final input for Knodle, for computational and conceptual purposes. But the code is written with scaleability in mind. The inclusion of Modifiers can at any point be included and would only require mirroring of the steps in the second notebook, to also include the Mod dataset. The inclusion of CompositeMention would merely require the labeling function to include another for loop and clause to map the occurence of a term of DiseaseClass or SpecificDisease followed by another, with an instance of and, or or / \\ between them. Given that the following preprocessing pipeline will only deal with unigrams, the ngram creation pipeline would need to be mirrored for a bigger set for this as well.\n",
    "\n",
    "Further potential for performance increase lies in the final inclusion of all the processed datasets all the while adjusting the sampling parameter to maximize the quality of the input with regards to the computational possibilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 1: Given the large size of the original dataset, in order to provide a proof of concept, only a subset is used, yet the pipelines are built in a way that the greater whole could be passed through in batches/chunks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: In a subsequent sections all of the prevously processed elements shall be exported and  later on imported in bulk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section each of the datasets in use will be examined, the relevant sections are stripped from them and further preprocessed into lists of strings.\n",
    "For this we remove stopwords, punctuation and numbers as well as normalize the input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import scipy\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "import copy\n",
    "import string\n",
    "\n",
    "punctuation = string.punctuation.replace('/', '')\n",
    "punctuation = punctuation.replace('\\\\', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>SHORT_TITLE</th>\n",
       "      <th>LONG_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>01166</td>\n",
       "      <td>TB pneumonia-oth test</td>\n",
       "      <td>Tuberculous pneumonia [any form], tubercle bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>01170</td>\n",
       "      <td>TB pneumothorax-unspec</td>\n",
       "      <td>Tuberculous pneumothorax, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>01171</td>\n",
       "      <td>TB pneumothorax-no exam</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>01172</td>\n",
       "      <td>TB pneumothorx-exam unkn</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>01173</td>\n",
       "      <td>TB pneumothorax-micro dx</td>\n",
       "      <td>Tuberculous pneumothorax, tubercle bacilli fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID ICD9_CODE               SHORT_TITLE  \\\n",
       "0     174     01166     TB pneumonia-oth test   \n",
       "1     175     01170    TB pneumothorax-unspec   \n",
       "2     176     01171   TB pneumothorax-no exam   \n",
       "3     177     01172  TB pneumothorx-exam unkn   \n",
       "4     178     01173  TB pneumothorax-micro dx   \n",
       "\n",
       "                                          LONG_TITLE  \n",
       "0  Tuberculous pneumonia [any form], tubercle bac...  \n",
       "1              Tuberculous pneumothorax, unspecified  \n",
       "2  Tuberculous pneumothorax, bacteriological or h...  \n",
       "3  Tuberculous pneumothorax, bacteriological or h...  \n",
       "4  Tuberculous pneumothorax, tubercle bacilli fou...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_ICD_DIAGNOSES=pd.read_csv('../../../mimic-iii-clinical-database-1.4/D_ICD_DIAGNOSES.csv', sep=',', header=0)\n",
    "D_ICD_DIAGNOSES.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiseaseClass1=D_ICD_DIAGNOSES.loc[:,'SHORT_TITLE']\n",
    "DC1=set(DiseaseClass1.values.tolist()) \n",
    "SpecificDisease1=D_ICD_DIAGNOSES.loc[:,'LONG_TITLE']\n",
    "SD1=set(SpecificDisease1.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiseaseName</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>AltDiseaseIDs</th>\n",
       "      <th>Definition</th>\n",
       "      <th>ParentIDs</th>\n",
       "      <th>TreeNumbers</th>\n",
       "      <th>ParentTreeNumbers</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>SlimMappings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10p Deletion Syndrome (Partial)</td>\n",
       "      <td>MESH:C538288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D002872|MESH:D025063</td>\n",
       "      <td>C16.131.260/C538288|C16.320.180/C538288|C23.55...</td>\n",
       "      <td>C16.131.260|C16.320.180|C23.550.210.050.500.500</td>\n",
       "      <td>Chromosome 10, 10p- Partial|Chromosome 10, mon...</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13q deletion syndrome</td>\n",
       "      <td>MESH:C535484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D002872|MESH:D025063</td>\n",
       "      <td>C16.131.260/C535484|C16.320.180/C535484|C23.55...</td>\n",
       "      <td>C16.131.260|C16.320.180|C23.550.210.050.500.500</td>\n",
       "      <td>Chromosome 13q deletion|Chromosome 13q deletio...</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15q24 Microdeletion</td>\n",
       "      <td>MESH:C579849</td>\n",
       "      <td>DO:DOID:0060395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D002872|MESH:D008607|MESH:D025063</td>\n",
       "      <td>C10.597.606.360/C579849|C16.131.260/C579849|C1...</td>\n",
       "      <td>C10.597.606.360|C16.131.260|C16.320.180|C23.55...</td>\n",
       "      <td>15q24 Deletion|15q24 Microdeletion Syndrome|In...</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16p11.2 Deletion Syndrome</td>\n",
       "      <td>MESH:C579850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D001321|MESH:D002872|MESH:D008607|MESH:D0...</td>\n",
       "      <td>C10.597.606.360/C579850|C16.131.260/C579850|C1...</td>\n",
       "      <td>C10.597.606.360|C16.131.260|C16.320.180|C23.55...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17,20-Lyase Deficiency, Isolated</td>\n",
       "      <td>MESH:C567076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D000312</td>\n",
       "      <td>C12.050.351.875.253.090.500/C567076|C12.200.70...</td>\n",
       "      <td>C12.050.351.875.253.090.500|C12.200.706.316.09...</td>\n",
       "      <td>17-Alpha-Hydroxylase-17,20-Lyase Deficiency, C...</td>\n",
       "      <td>Congenital abnormality|Endocrine system diseas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DiseaseName     DiseaseID    AltDiseaseIDs Definition  \\\n",
       "0   10p Deletion Syndrome (Partial)  MESH:C538288              NaN        NaN   \n",
       "1             13q deletion syndrome  MESH:C535484              NaN        NaN   \n",
       "2               15q24 Microdeletion  MESH:C579849  DO:DOID:0060395        NaN   \n",
       "3         16p11.2 Deletion Syndrome  MESH:C579850              NaN        NaN   \n",
       "4  17,20-Lyase Deficiency, Isolated  MESH:C567076              NaN        NaN   \n",
       "\n",
       "                                           ParentIDs  \\\n",
       "0                          MESH:D002872|MESH:D025063   \n",
       "1                          MESH:D002872|MESH:D025063   \n",
       "2             MESH:D002872|MESH:D008607|MESH:D025063   \n",
       "3  MESH:D001321|MESH:D002872|MESH:D008607|MESH:D0...   \n",
       "4                                       MESH:D000312   \n",
       "\n",
       "                                         TreeNumbers  \\\n",
       "0  C16.131.260/C538288|C16.320.180/C538288|C23.55...   \n",
       "1  C16.131.260/C535484|C16.320.180/C535484|C23.55...   \n",
       "2  C10.597.606.360/C579849|C16.131.260/C579849|C1...   \n",
       "3  C10.597.606.360/C579850|C16.131.260/C579850|C1...   \n",
       "4  C12.050.351.875.253.090.500/C567076|C12.200.70...   \n",
       "\n",
       "                                   ParentTreeNumbers  \\\n",
       "0    C16.131.260|C16.320.180|C23.550.210.050.500.500   \n",
       "1    C16.131.260|C16.320.180|C23.550.210.050.500.500   \n",
       "2  C10.597.606.360|C16.131.260|C16.320.180|C23.55...   \n",
       "3  C10.597.606.360|C16.131.260|C16.320.180|C23.55...   \n",
       "4  C12.050.351.875.253.090.500|C12.200.706.316.09...   \n",
       "\n",
       "                                            Synonyms  \\\n",
       "0  Chromosome 10, 10p- Partial|Chromosome 10, mon...   \n",
       "1  Chromosome 13q deletion|Chromosome 13q deletio...   \n",
       "2  15q24 Deletion|15q24 Microdeletion Syndrome|In...   \n",
       "3                                                NaN   \n",
       "4  17-Alpha-Hydroxylase-17,20-Lyase Deficiency, C...   \n",
       "\n",
       "                                        SlimMappings  \n",
       "0  Congenital abnormality|Genetic disease (inborn...  \n",
       "1  Congenital abnormality|Genetic disease (inborn...  \n",
       "2  Congenital abnormality|Genetic disease (inborn...  \n",
       "3  Congenital abnormality|Genetic disease (inborn...  \n",
       "4  Congenital abnormality|Endocrine system diseas...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTD_diseases=pd.read_csv('./data/CTD_diseases.csv', sep=',', header=0)\n",
    "CTD_diseases.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiseaseClass2=CTD_diseases.loc[:,'SlimMappings']\n",
    "DC2_input= DiseaseClass2.values.tolist()\n",
    "DC2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_pipe(input_list, new_list):\n",
    "    for former_row in input_list:\n",
    "        Sublist=str(former_row).split('|')\n",
    "        for item in Sublist:\n",
    "            new_list.append(item) \n",
    "    new_list=set(new_list)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC2 = split_on_pipe(DC2_input, DC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecificDisease2=CTD_diseases.loc[:,'DiseaseName']\n",
    "SD2_input=set(SpecificDisease2.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD2=[]\n",
    "SD2 = split_on_pipe(SD2_input, SD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C100000</th>\n",
       "      <th>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C100000&gt;</th>\n",
       "      <th>C99521</th>\n",
       "      <th>Percutaneous Coronary Intervention for ST Elevation Myocardial Infarction-Stable-Over 12 Hours From Symptom Onset|PERCUTANEOUS CORONARY INTERVENTION (PCI) FOR ST ELEVATION MYOCARDIAL INFARCTION (STEMI) (STABLE, &gt;12 HRS FROM SYMPTOM ONSET)</th>\n",
       "      <th>A percutaneous coronary intervention is necessary for a myocardial infarction that presents with ST segment elevation and the subject does not have recurrent or persistent symptoms, symptoms of heart failure or ventricular arrhythmia. The presentation is past twelve hours since onset of symptoms. (ACC)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Therapeutic or Preventive Procedure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C100012</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C50797</td>\n",
       "      <td>Severe Cardiac Valve Regurgitation</td>\n",
       "      <td>Evidence of severe retrograde blood flow throu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C100020</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C35317</td>\n",
       "      <td>Three Vessel Coronary Disease|THREE VESSEL DIS...</td>\n",
       "      <td>There was greater than or equal to 50% stenosi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C100023</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C35317</td>\n",
       "      <td>Two Vessel Coronary Disease|TWO VESSEL DISEASE</td>\n",
       "      <td>There was greater than or equal to 50% stenosi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>C100062</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C99938</td>\n",
       "      <td>Chronic Total Coronary Artery Occlusion</td>\n",
       "      <td>Prolonged complete obstruction of the coronary...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>C100070</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C35279</td>\n",
       "      <td>Coronary Venous Dissection</td>\n",
       "      <td>A tear within the wall of a coronary vein. (ACC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C100000 <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C100000>  \\\n",
       "12  C100012  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "21  C100020  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "24  C100023  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "67  C100062  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "76  C100070  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "\n",
       "    C99521  \\\n",
       "12  C50797   \n",
       "21  C35317   \n",
       "24  C35317   \n",
       "67  C99938   \n",
       "76  C35279   \n",
       "\n",
       "   Percutaneous Coronary Intervention for ST Elevation Myocardial Infarction-Stable-Over 12 Hours From Symptom Onset|PERCUTANEOUS CORONARY INTERVENTION (PCI) FOR ST ELEVATION MYOCARDIAL INFARCTION (STEMI) (STABLE, >12 HRS FROM SYMPTOM ONSET)  \\\n",
       "12                 Severe Cardiac Valve Regurgitation                                                                                                                                                                                               \n",
       "21  Three Vessel Coronary Disease|THREE VESSEL DIS...                                                                                                                                                                                               \n",
       "24     Two Vessel Coronary Disease|TWO VESSEL DISEASE                                                                                                                                                                                               \n",
       "67            Chronic Total Coronary Artery Occlusion                                                                                                                                                                                               \n",
       "76                         Coronary Venous Dissection                                                                                                                                                                                               \n",
       "\n",
       "   A percutaneous coronary intervention is necessary for a myocardial infarction that presents with ST segment elevation and the subject does not have recurrent or persistent symptoms, symptoms of heart failure or ventricular arrhythmia. The presentation is past twelve hours since onset of symptoms. (ACC)  \\\n",
       "12  Evidence of severe retrograde blood flow throu...                                                                                                                                                                                                                                                                \n",
       "21  There was greater than or equal to 50% stenosi...                                                                                                                                                                                                                                                                \n",
       "24  There was greater than or equal to 50% stenosi...                                                                                                                                                                                                                                                                \n",
       "67  Prolonged complete obstruction of the coronary...                                                                                                                                                                                                                                                                \n",
       "76   A tear within the wall of a coronary vein. (ACC)                                                                                                                                                                                                                                                                \n",
       "\n",
       "   Unnamed: 5 Unnamed: 6 Therapeutic or Preventive Procedure  \n",
       "12        NaN        NaN                 Disease or Syndrome  \n",
       "21        NaN        NaN                 Disease or Syndrome  \n",
       "24        NaN        NaN                 Disease or Syndrome  \n",
       "67        NaN        NaN                 Disease or Syndrome  \n",
       "76        NaN        NaN                 Disease or Syndrome  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCI9d=pd.read_csv('./data/Thesaurus.text', sep='\\t')\n",
    "NCI9d_disease_subset=NCI9d.loc[NCI9d['Therapeutic or Preventive Procedure'] == 'Disease or Syndrome']\n",
    "NCI9d_disease_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecificDisease4=NCI9d_disease_subset.iloc[:,3]\n",
    "SD3_input=SpecificDisease4.values.tolist()\n",
    "\n",
    "SD3=[]\n",
    "SD3=split_on_pipe(SD3_input, SD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ULMS_terminology=pd.read_csv(\"./data/NC.DB\", sep = '|')\n",
    "Modifiers=ULMS_terminology.iloc[:,0]\n",
    "Mod_pre=Modifiers.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_brackets(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod=[]\n",
    "\n",
    "for term in Mod_pre:\n",
    "    a=skip_brackets(str(term))\n",
    "    Mod.append(a)\n",
    "\n",
    "for term in Mod_pre:\n",
    "    x=term.replace('(','').replace(')','').replace(r'[0-9]+', '')\n",
    "    Mod.append(x)\n",
    "    \n",
    "Mod=set(Mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(list):\n",
    "    [str(x).lower() for x in list]\n",
    "    return list\n",
    "\n",
    "SD1 = lower('SD1')\n",
    "SD2 = lower('SD2')\n",
    "SD3 = lower('SD3')\n",
    "DC1 = lower('DC1')\n",
    "DC2 = lower('DC2')\n",
    "Mod = lower('Mod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring and Pruning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the requirements for a total n-gram upper limit, we take a look at our keyword element distributions.\n",
    "At the same time we will remove stopwords, punctuation and digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_DC1 = [len(element.split()) for element in DC1]  \n",
    "print(Counter(num_words_DC1))\n",
    "\n",
    "DC1_tidy = []\n",
    "\n",
    "def no_stop(list, tidy_list):\n",
    "    temp_cleaned = []\n",
    "    temp_cleaned=copy.deepcopy(list)\n",
    "    for string in temp_cleaned:\n",
    "        if string not in stopwords:\n",
    "            tidy_list.append(string.translate(str.maketrans('', '', punctuation)))\n",
    "\n",
    "\n",
    "no_stop(DC1, DC1_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_DC2 = [len(element.split()) for element in DC2]  \n",
    "print(Counter(num_words_DC2))\n",
    "\n",
    "DC2_tidy = []\n",
    "\n",
    "no_stop(DC2, DC2_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD1 = [len(element.split()) for element in SD1]  \n",
    "print(Counter(num_words_SD1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD3 = [len(element.split()) for element in SD3]  \n",
    "print(Counter(num_words_SD3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Pretty printing has been turned OFF\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD1 = [len(element.split()) for element in SD1]  \n",
    "#print(Counter(num_words_SD1))\n",
    "SD1_tidy = []\n",
    "no_stop(SD1, SD1_tidy)\n",
    "\n",
    "%pprint\n",
    "num_words_SD1_tidy = [len(element.split()) for element in SD1_tidy]  \n",
    "print(Counter(num_words_SD1_tidy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({1: 3})\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD2 = [len(element.split()) for element in SD2]  \n",
    "print(Counter(num_words_SD2))\n",
    "\n",
    "SD2_tidy = []\n",
    "no_stop(SD2, SD2_tidy)\n",
    "\n",
    "num_words_SD2_tidy = [len(element.split()) for element in SD2_tidy]  \n",
    "print(Counter(num_words_SD2_tidy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD3 = [len(element.split()) for element in SD3]  \n",
    "#print(Counter(num_words_SD3))\n",
    "\n",
    "SD3_tidy = []\n",
    "no_stop(SD3, SD3_tidy)\n",
    "\n",
    "num_words_SD3_tidy = [len(element.split()) for element in SD3_tidy]  \n",
    "print(Counter(num_words_SD3_tidy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({1: 3})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_Mod = [len(element.split()) for element in Mod]  \n",
    "print(Counter(num_words_Mod))\n",
    "\n",
    "Mod_tidy = []\n",
    "no_stop(Mod, Mod_tidy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sensible cutoff point where most of our keywords are retained for rules would be 7_grams. In the nextstep, yet for testing purposes we will proceed with unigrams, in the following the lists could be ridded of any elements with more terms within them. The proceding creation of ngrams would need it's paramters set accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_digit(input, output):\n",
    "    for element in input:\n",
    "        element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "        if len(element.split()) < 2:\n",
    "                output.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC1_trim = []\n",
    "no_digit(DC1_tidy, DC1_trim)\n",
    "\n",
    "DC2_trim = []\n",
    "no_digit(DC2_tidy, DC2_trim)\n",
    "\n",
    "SD1_trim = []\n",
    "no_digit(SD1_tidy, SD1_trim)\n",
    "\n",
    "SD2_trim = []\n",
    "no_digit(SD2_tidy, SD2_trim)\n",
    "\n",
    "SD3_trim = []\n",
    "no_digit(SD3_tidy, SD3_trim)\n",
    "\n",
    "Mod_trim = []\n",
    "no_digit(Mod_tidy, Mod_trim)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to mittigate the problems of the excessive RAM usage, we will be sampling the dataset heavily and only use 1/100 of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_notes = pd.read_csv('../../../mimic-iii-clinical-database-1.4/NOTEEVENTS.csv', low_memory=False)\n",
    "# df_notes = df_notes.sample(frac=0.01, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes_text = df_notes.TEXT\n",
    "# notes_text = notes_text.str.replace(r'\\[\\*\\*(.*?)\\*\\*\\]', '') # extract tag placeholders\n",
    "# notes_text = notes_text.str.replace(r'[0-9]+', '') # extract all digits\n",
    "# punctuation = string.punctuation.replace('/', '')\n",
    "# punctuation = punctuation.replace('\\\\', '') # excluding slashes from punctuation removal, since we need them to match with some disease\n",
    "\n",
    "# notes_text = notes_text.str.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "# stopwords = stopwords.words('english')\n",
    "# stopwords.remove('and')\n",
    "# stopwords.remove('or')\n",
    "# notes_text = notes_text.apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes_text.to_csv('../data/notes_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our lists as well as the traing data are sufficiently tidy, we store them for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filepath, variable):\n",
    "    try:\n",
    "        os.remove('filepath')\n",
    "    except OSError:\n",
    "        pass\n",
    "    with open(filepath, 'w') as fp:\n",
    "        for item in variable:\n",
    "            #writes each entry on a new line\n",
    "            fp.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "write_to_file('./data/DC1.txt', DC1_trim)\n",
    "\n",
    "write_to_file('./data/DC2.txt', DC2_trim)\n",
    "\n",
    "write_to_file('./data/SD1.txt', SD1_trim)\n",
    "\n",
    "write_to_file('./data/SD2.txt', SD2_trim)\n",
    "\n",
    "write_to_file('./data/SD3.txt', SD3_trim)\n",
    "\n",
    "write_to_file('./data/Mod.txt', Mod_trim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the preprocessing of the test and dev data - NCBI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same steps are used here, the data is cleaned, stripped of unwanted elements, brought into shape of the future training data and exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_t = []\n",
    "labels_t = []\n",
    "\n",
    "file = open('./data/NCBItestset_corpus.txt', 'r')\n",
    "Lines = file.readlines()\n",
    "  \n",
    "for line in Lines:\n",
    "    if line.find(\"|\") > 0:\n",
    "        text_t.append(line)\n",
    "    elif len(line) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        labels_t.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_d = []\n",
    "labels_d = []\n",
    "\n",
    "file = open('./data/NCBIdevelopset_corpus.txt', 'r')\n",
    "Lines = file.readlines()\n",
    "  \n",
    "for line in Lines:\n",
    "    if line.find(\"|\") > 0:\n",
    "        text_d.append(line)\n",
    "    elif len(line) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        labels_d.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.DataFrame([elem.split(\"|\") for elem in text_t])\n",
    "test_text.drop(test_text.columns[[1,3]],axis=1, inplace=True)\n",
    "test_text.columns = ['ID','Text']\n",
    "test_text[test_text.columns[0]] = test_text[test_text.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "test_text_f = test_text[test_text['ID'] == 0].index\n",
    "test_text.drop(test_text_f, inplace=True)\n",
    "test_text = test_text.groupby(['ID']).agg({'Text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_text = pd.DataFrame([elem.split(\"|\") for elem in text_d])\n",
    "dev_text.drop(dev_text.columns[[1,3]],axis=1, inplace=True)\n",
    "dev_text.columns = ['ID','Text']\n",
    "dev_text[dev_text.columns[0]] = dev_text[dev_text.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "dev_text_f = dev_text[dev_text['ID'] == 0].index\n",
    "dev_text.drop(dev_text_f, inplace=True)\n",
    "dev_text = dev_text.groupby(['ID']).agg({'Text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = pd.DataFrame([elem.split('\\t') for elem in labels_t])\n",
    "test_label.drop(test_label.columns[[1,2,5]],axis=1, inplace=True)\n",
    "test_label.columns =['ID', 'Label', 'Class']\n",
    "test_label[test_label.columns[0]] = test_label[test_label.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "test_label_f = test_label[test_label['ID'] == 0].index\n",
    "test_label.drop(test_label_f, inplace=True)\n",
    "test_label = test_label[test_label['Label'].str.count(' ') == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label = pd.DataFrame([elem.split('\\t') for elem in labels_d])\n",
    "dev_label.drop(dev_label.columns[[1,2,5]],axis=1, inplace=True)\n",
    "dev_label.columns =['ID', 'Label', 'Class']\n",
    "dev_label[dev_label.columns[0]] = dev_label[dev_label.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "dev_label_f = dev_label[dev_label['ID'] == 0].index\n",
    "dev_label.drop(dev_label_f, inplace=True)\n",
    "dev_label = dev_label[dev_label['Label'].str.count(' ') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "for char in punctuation:\n",
    "    test_label['Label'] = test_label['Label'].str.replace(char, '')\n",
    "       \n",
    "for char in digits:\n",
    "    test_label['Label'] = test_label['Label'].str.replace(char, '')\n",
    "    \n",
    "for char in punctuation:\n",
    "    test_text['Text'] = test_text['Text'].str.replace(char, '')\n",
    "\n",
    "for char in digits:\n",
    "    test_text['Text'] = test_text['Text'].str.replace(char, '')\n",
    "\n",
    "test_text[\"Text\"] = test_text[\"Text\"].str.lower()\n",
    "test_label[\"Label\"] = test_label[\"Label\"].str.lower()\n",
    "test_text[\"Text\"] = test_text[\"Text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "for char in punctuation:\n",
    "    dev_label['Label'] = dev_label['Label'].str.replace(char, '')\n",
    "       \n",
    "for char in digits:\n",
    "    dev_label['Label'] = dev_label['Label'].str.replace(char, '')\n",
    "    \n",
    "for char in punctuation:\n",
    "    dev_text['Text'] = dev_text['Text'].str.replace(char, '')\n",
    "\n",
    "for char in digits:\n",
    "    dev_text['Text'] = dev_text['Text'].str.replace(char, '')\n",
    "\n",
    "dev_text[\"Text\"] = dev_text[\"Text\"].str.lower()\n",
    "dev_label[\"Label\"] = dev_label[\"Label\"].str.lower()\n",
    "dev_text[\"Text\"] = dev_text[\"Text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9050866</td>\n",
       "      <td>ataxiatelangiectasia</td>\n",
       "      <td>Modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9050866</td>\n",
       "      <td>ataxiatelangiectasia</td>\n",
       "      <td>Modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9050866</td>\n",
       "      <td>ataxiatelangiectasia</td>\n",
       "      <td>Modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8755645</td>\n",
       "      <td>fed</td>\n",
       "      <td>SpecificDisease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8755645</td>\n",
       "      <td>fed</td>\n",
       "      <td>Modifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                 Label            Class\n",
       "7   9050866  ataxiatelangiectasia         Modifier\n",
       "8   9050866  ataxiatelangiectasia         Modifier\n",
       "9   9050866  ataxiatelangiectasia         Modifier\n",
       "18  8755645                   fed  SpecificDisease\n",
       "19  8755645                   fed         Modifier"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>hereditary deficiency fifth component compleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941901</th>\n",
       "      <td>low levels beta hexosaminidase healthy individ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993342</th>\n",
       "      <td>chromosomal order genes controlling major hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288106</th>\n",
       "      <td>clustering missense mutations ataxiatelangiect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294109</th>\n",
       "      <td>myotonic dystrophy protein kinase involved mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Text\n",
       "ID                                                        \n",
       "932197   hereditary deficiency fifth component compleme...\n",
       "941901   low levels beta hexosaminidase healthy individ...\n",
       "993342   chromosomal order genes controlling major hist...\n",
       "9288106  clustering missense mutations ataxiatelangiect...\n",
       "9294109  myotonic dystrophy protein kinase involved mod..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text['Terms'] = test_text['Text'].str.split(' ')\n",
    "test_word=test_text.explode('Terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>brca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>secreted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>exhibits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>granin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Terms\n",
       "ID                 \n",
       "8589722        brca\n",
       "8589722    secreted\n",
       "8589722    exhibits\n",
       "8589722  properties\n",
       "8589722      granin"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_text['Terms'] = dev_text['Text'].str.split(' ')\n",
    "dev_word=dev_text.explode('Terms')\n",
    "dev_word.drop('Text', axis=1, inplace=True)\n",
    "dev_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>hereditary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>fifth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>complement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Terms\n",
       "ID                \n",
       "932197  hereditary\n",
       "932197  deficiency\n",
       "932197       fifth\n",
       "932197   component\n",
       "932197  complement"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word.drop('Text', axis=1, inplace=True)\n",
    "test_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_fin=test_word.merge(test_label, left_on=['ID','Terms'], right_on = ['ID','Label'], how='left')\n",
    "Test_fin.drop('Label', axis=1, inplace=True)\n",
    "Test_fin.fillna('OTHER', axis=1, inplace=True)\n",
    "Test_fin_f = Test_fin[Test_fin['Class'] == 'Modifier'].index\n",
    "Test_fin.drop(Test_fin_f, inplace=True)\n",
    "Test_fin_f = Test_fin[Test_fin['Class'] == 'CompositeMention'].index\n",
    "Test_fin.drop(Test_fin_f, inplace=True)\n",
    "Test_fin=Test_fin[Test_fin.ID != 9472666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dev_fin=dev_word.merge(dev_label, left_on=['ID','Terms'], right_on = ['ID','Label'], how='left')\n",
    "Dev_fin.drop('Label', axis=1, inplace=True)\n",
    "Dev_fin.fillna('OTHER', axis=1, inplace=True)\n",
    "Dev_fin_f = Dev_fin[Dev_fin['Class'] == 'Modifier'].index\n",
    "Dev_fin.drop(Dev_fin_f, inplace=True)\n",
    "Dev_fin_f = Dev_fin[Dev_fin['Class'] == 'CompositeMention'].index\n",
    "Dev_fin.drop(Dev_fin_f, inplace=True)\n",
    "Dev_fin.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_fin.to_csv('./data/test_fin.csv', index=False)\n",
    "\n",
    "Dev_fin.to_csv('./data/dev_fin.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit ('3.7.15')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 23 2022, 13:36:42) \n[GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66d5c63fb80eb6fd04af604839a1d74609fa54c5a8a540ddfe18aa77248ed3d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
