{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Disease Named Entity Recognition (D-NER)\n",
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will utilize the Mimic III dataset as training data for a Kndole sequence tagger model.\n",
    "For the development and evaluation of the model, the NCIT dataset will be used, for which the existing tags are as follows:\n",
    "DiseaseClass, SpecificDisease, Modifier, CompositeMention\n",
    "In order to supplement the Mimic III dataset for this task, three other datasets where consulted to aid in the fitting of specific categories for the matching with the structure of the classes:\n",
    "\n",
    "National Cancer Institute Thesaurus: NCI9d - Thesaurus.txt: NCI Thesaurus Version 22.09d - flattened from the owl format \n",
    "from their own webpage: https://evs.nci.nih.gov/evs-download/thesaurus-downloads\n",
    "\n",
    "The vast ULMS dataset (Unified Medical Language System),\n",
    "after authentification, to be accessed at: https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html\n",
    "Specifically the table NB.DB\n",
    "\n",
    "MEDIC - CTD's MEDIC disease vocabulary is a modified subset of descriptors from the “Diseases” [C] branch of the U.S. National Library of Medicine's Medical Subject Headings (MeSH®),combined with genetic disorders from the Online Mendelian Inheritance in Man® (OMIM®) database. Comparative Toxicogenomics Database: https://ctdbase.org/downloads/#alldiseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 1: In a subsequent section all of the prevously processed elements shall be exported and imported, for reuse it is convenient to simply skip to this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: All the data which is too big for github, will be available for download through a link in the repository discription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section each of the datasets in use will be examined, the relevant sections stripped from them and further processed into lists of strings to be used in rule based labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import scipy\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "import copy\n",
    "import string\n",
    "\n",
    "punctuation = string.punctuation.replace('/', '')\n",
    "punctuation = punctuation.replace('\\\\', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>SHORT_TITLE</th>\n",
       "      <th>LONG_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>01166</td>\n",
       "      <td>TB pneumonia-oth test</td>\n",
       "      <td>Tuberculous pneumonia [any form], tubercle bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>01170</td>\n",
       "      <td>TB pneumothorax-unspec</td>\n",
       "      <td>Tuberculous pneumothorax, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>01171</td>\n",
       "      <td>TB pneumothorax-no exam</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>01172</td>\n",
       "      <td>TB pneumothorx-exam unkn</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>01173</td>\n",
       "      <td>TB pneumothorax-micro dx</td>\n",
       "      <td>Tuberculous pneumothorax, tubercle bacilli fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID ICD9_CODE               SHORT_TITLE  \\\n",
       "0     174     01166     TB pneumonia-oth test   \n",
       "1     175     01170    TB pneumothorax-unspec   \n",
       "2     176     01171   TB pneumothorax-no exam   \n",
       "3     177     01172  TB pneumothorx-exam unkn   \n",
       "4     178     01173  TB pneumothorax-micro dx   \n",
       "\n",
       "                                          LONG_TITLE  \n",
       "0  Tuberculous pneumonia [any form], tubercle bac...  \n",
       "1              Tuberculous pneumothorax, unspecified  \n",
       "2  Tuberculous pneumothorax, bacteriological or h...  \n",
       "3  Tuberculous pneumothorax, bacteriological or h...  \n",
       "4  Tuberculous pneumothorax, tubercle bacilli fou...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_ICD_DIAGNOSES=pd.read_csv('../../../mimic-iii-clinical-database-1.4/D_ICD_DIAGNOSES.csv', sep=',', header=0)\n",
    "D_ICD_DIAGNOSES.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiseaseClass1=D_ICD_DIAGNOSES.loc[:,'SHORT_TITLE']\n",
    "DC1=set(DiseaseClass1.values.tolist()) \n",
    "SpecificDisease1=D_ICD_DIAGNOSES.loc[:,'LONG_TITLE']\n",
    "SD1=set(SpecificDisease1.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiseaseName</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>AltDiseaseIDs</th>\n",
       "      <th>Definition</th>\n",
       "      <th>ParentIDs</th>\n",
       "      <th>TreeNumbers</th>\n",
       "      <th>ParentTreeNumbers</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>SlimMappings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10p Deletion Syndrome (Partial)</td>\n",
       "      <td>MESH:C538288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D002872|MESH:D025063</td>\n",
       "      <td>C16.131.260/C538288|C16.320.180/C538288|C23.55...</td>\n",
       "      <td>C16.131.260|C16.320.180|C23.550.210.050.500.500</td>\n",
       "      <td>Chromosome 10, 10p- Partial|Chromosome 10, mon...</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13q deletion syndrome</td>\n",
       "      <td>MESH:C535484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D002872|MESH:D025063</td>\n",
       "      <td>C16.131.260/C535484|C16.320.180/C535484|C23.55...</td>\n",
       "      <td>C16.131.260|C16.320.180|C23.550.210.050.500.500</td>\n",
       "      <td>Chromosome 13q deletion|Chromosome 13q deletio...</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15q24 Microdeletion</td>\n",
       "      <td>MESH:C579849</td>\n",
       "      <td>DO:DOID:0060395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D002872|MESH:D008607|MESH:D025063</td>\n",
       "      <td>C10.597.606.360/C579849|C16.131.260/C579849|C1...</td>\n",
       "      <td>C10.597.606.360|C16.131.260|C16.320.180|C23.55...</td>\n",
       "      <td>15q24 Deletion|15q24 Microdeletion Syndrome|In...</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16p11.2 Deletion Syndrome</td>\n",
       "      <td>MESH:C579850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D001321|MESH:D002872|MESH:D008607|MESH:D0...</td>\n",
       "      <td>C10.597.606.360/C579850|C16.131.260/C579850|C1...</td>\n",
       "      <td>C10.597.606.360|C16.131.260|C16.320.180|C23.55...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17,20-Lyase Deficiency, Isolated</td>\n",
       "      <td>MESH:C567076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D000312</td>\n",
       "      <td>C12.050.351.875.253.090.500/C567076|C12.200.70...</td>\n",
       "      <td>C12.050.351.875.253.090.500|C12.200.706.316.09...</td>\n",
       "      <td>17-Alpha-Hydroxylase-17,20-Lyase Deficiency, C...</td>\n",
       "      <td>Congenital abnormality|Endocrine system diseas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DiseaseName     DiseaseID    AltDiseaseIDs Definition  \\\n",
       "0   10p Deletion Syndrome (Partial)  MESH:C538288              NaN        NaN   \n",
       "1             13q deletion syndrome  MESH:C535484              NaN        NaN   \n",
       "2               15q24 Microdeletion  MESH:C579849  DO:DOID:0060395        NaN   \n",
       "3         16p11.2 Deletion Syndrome  MESH:C579850              NaN        NaN   \n",
       "4  17,20-Lyase Deficiency, Isolated  MESH:C567076              NaN        NaN   \n",
       "\n",
       "                                           ParentIDs  \\\n",
       "0                          MESH:D002872|MESH:D025063   \n",
       "1                          MESH:D002872|MESH:D025063   \n",
       "2             MESH:D002872|MESH:D008607|MESH:D025063   \n",
       "3  MESH:D001321|MESH:D002872|MESH:D008607|MESH:D0...   \n",
       "4                                       MESH:D000312   \n",
       "\n",
       "                                         TreeNumbers  \\\n",
       "0  C16.131.260/C538288|C16.320.180/C538288|C23.55...   \n",
       "1  C16.131.260/C535484|C16.320.180/C535484|C23.55...   \n",
       "2  C10.597.606.360/C579849|C16.131.260/C579849|C1...   \n",
       "3  C10.597.606.360/C579850|C16.131.260/C579850|C1...   \n",
       "4  C12.050.351.875.253.090.500/C567076|C12.200.70...   \n",
       "\n",
       "                                   ParentTreeNumbers  \\\n",
       "0    C16.131.260|C16.320.180|C23.550.210.050.500.500   \n",
       "1    C16.131.260|C16.320.180|C23.550.210.050.500.500   \n",
       "2  C10.597.606.360|C16.131.260|C16.320.180|C23.55...   \n",
       "3  C10.597.606.360|C16.131.260|C16.320.180|C23.55...   \n",
       "4  C12.050.351.875.253.090.500|C12.200.706.316.09...   \n",
       "\n",
       "                                            Synonyms  \\\n",
       "0  Chromosome 10, 10p- Partial|Chromosome 10, mon...   \n",
       "1  Chromosome 13q deletion|Chromosome 13q deletio...   \n",
       "2  15q24 Deletion|15q24 Microdeletion Syndrome|In...   \n",
       "3                                                NaN   \n",
       "4  17-Alpha-Hydroxylase-17,20-Lyase Deficiency, C...   \n",
       "\n",
       "                                        SlimMappings  \n",
       "0  Congenital abnormality|Genetic disease (inborn...  \n",
       "1  Congenital abnormality|Genetic disease (inborn...  \n",
       "2  Congenital abnormality|Genetic disease (inborn...  \n",
       "3  Congenital abnormality|Genetic disease (inborn...  \n",
       "4  Congenital abnormality|Endocrine system diseas...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTD_diseases=pd.read_csv('./data/CTD_diseases.csv', sep=',', header=0)\n",
    "CTD_diseases.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiseaseClass2=CTD_diseases.loc[:,'SlimMappings']\n",
    "DC2_input= DiseaseClass2.values.tolist()\n",
    "DC2=[]\n",
    "for former_row in DC2_input:\n",
    "    Sublist=str(former_row).split('|')\n",
    "    for item in Sublist:\n",
    "        DC2.append(item) \n",
    "DC2=set(DC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecificDisease2=CTD_diseases.loc[:,'DiseaseName']\n",
    "SD2_input=set(SpecificDisease2.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD2=[]\n",
    "for former_row in SD2_input:\n",
    "    Sublist=str(former_row).split('|')\n",
    "    for item in Sublist:\n",
    "        SD2.append(item) \n",
    "SD2=set(SD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C100000</th>\n",
       "      <th>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C100000&gt;</th>\n",
       "      <th>C99521</th>\n",
       "      <th>Percutaneous Coronary Intervention for ST Elevation Myocardial Infarction-Stable-Over 12 Hours From Symptom Onset|PERCUTANEOUS CORONARY INTERVENTION (PCI) FOR ST ELEVATION MYOCARDIAL INFARCTION (STEMI) (STABLE, &gt;12 HRS FROM SYMPTOM ONSET)</th>\n",
       "      <th>A percutaneous coronary intervention is necessary for a myocardial infarction that presents with ST segment elevation and the subject does not have recurrent or persistent symptoms, symptoms of heart failure or ventricular arrhythmia. The presentation is past twelve hours since onset of symptoms. (ACC)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Therapeutic or Preventive Procedure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C100012</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C50797</td>\n",
       "      <td>Severe Cardiac Valve Regurgitation</td>\n",
       "      <td>Evidence of severe retrograde blood flow throu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C100020</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C35317</td>\n",
       "      <td>Three Vessel Coronary Disease|THREE VESSEL DIS...</td>\n",
       "      <td>There was greater than or equal to 50% stenosi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C100023</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C35317</td>\n",
       "      <td>Two Vessel Coronary Disease|TWO VESSEL DISEASE</td>\n",
       "      <td>There was greater than or equal to 50% stenosi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>C100062</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C99938</td>\n",
       "      <td>Chronic Total Coronary Artery Occlusion</td>\n",
       "      <td>Prolonged complete obstruction of the coronary...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>C100070</td>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>C35279</td>\n",
       "      <td>Coronary Venous Dissection</td>\n",
       "      <td>A tear within the wall of a coronary vein. (ACC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C100000 <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C100000>  \\\n",
       "12  C100012  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "21  C100020  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "24  C100023  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "67  C100062  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "76  C100070  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...             \n",
       "\n",
       "    C99521  \\\n",
       "12  C50797   \n",
       "21  C35317   \n",
       "24  C35317   \n",
       "67  C99938   \n",
       "76  C35279   \n",
       "\n",
       "   Percutaneous Coronary Intervention for ST Elevation Myocardial Infarction-Stable-Over 12 Hours From Symptom Onset|PERCUTANEOUS CORONARY INTERVENTION (PCI) FOR ST ELEVATION MYOCARDIAL INFARCTION (STEMI) (STABLE, >12 HRS FROM SYMPTOM ONSET)  \\\n",
       "12                 Severe Cardiac Valve Regurgitation                                                                                                                                                                                               \n",
       "21  Three Vessel Coronary Disease|THREE VESSEL DIS...                                                                                                                                                                                               \n",
       "24     Two Vessel Coronary Disease|TWO VESSEL DISEASE                                                                                                                                                                                               \n",
       "67            Chronic Total Coronary Artery Occlusion                                                                                                                                                                                               \n",
       "76                         Coronary Venous Dissection                                                                                                                                                                                               \n",
       "\n",
       "   A percutaneous coronary intervention is necessary for a myocardial infarction that presents with ST segment elevation and the subject does not have recurrent or persistent symptoms, symptoms of heart failure or ventricular arrhythmia. The presentation is past twelve hours since onset of symptoms. (ACC)  \\\n",
       "12  Evidence of severe retrograde blood flow throu...                                                                                                                                                                                                                                                                \n",
       "21  There was greater than or equal to 50% stenosi...                                                                                                                                                                                                                                                                \n",
       "24  There was greater than or equal to 50% stenosi...                                                                                                                                                                                                                                                                \n",
       "67  Prolonged complete obstruction of the coronary...                                                                                                                                                                                                                                                                \n",
       "76   A tear within the wall of a coronary vein. (ACC)                                                                                                                                                                                                                                                                \n",
       "\n",
       "   Unnamed: 5 Unnamed: 6 Therapeutic or Preventive Procedure  \n",
       "12        NaN        NaN                 Disease or Syndrome  \n",
       "21        NaN        NaN                 Disease or Syndrome  \n",
       "24        NaN        NaN                 Disease or Syndrome  \n",
       "67        NaN        NaN                 Disease or Syndrome  \n",
       "76        NaN        NaN                 Disease or Syndrome  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCI9d=pd.read_csv('./data/Thesaurus.text', sep='\\t')\n",
    "NCI9d_disease_subset=NCI9d.loc[NCI9d['Therapeutic or Preventive Procedure'] == 'Disease or Syndrome']\n",
    "NCI9d_disease_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecificDisease4=NCI9d_disease_subset.iloc[:,3]\n",
    "SD3_input=SpecificDisease4.values.tolist()\n",
    "\n",
    "SD3=[]\n",
    "for former_row in SD3_input:\n",
    "    Sublist=str(former_row).split('|')\n",
    "    for item in Sublist:\n",
    "        SD3.append(item) \n",
    "SD3=set(SD3)\n",
    "#print(SD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ULMS_terminology=pd.read_csv(\"./NC.DB\", sep = '|')\n",
    "Modifiers=ULMS_terminology.iloc[:,0]\n",
    "Mod_pre=Modifiers.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_brackets(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod=[]\n",
    "\n",
    "for term in Mod_pre:\n",
    "    a=skip_brackets(str(term))\n",
    "    Mod.append(a)\n",
    "\n",
    "for term in Mod_pre:\n",
    "    x=term.replace('(','').replace(')','').replace(r'[0-9]+', '')\n",
    "    Mod.append(x)\n",
    "    \n",
    "Mod=set(Mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD1 = [str(x).lower() for x in SD1]\n",
    "SD2 = [str(x).lower() for x in SD2]\n",
    "SD3 = [str(x).lower() for x in SD3]\n",
    "DC1 = [str(x).lower() for x in DC1]\n",
    "DC2 = [str(x).lower() for x in DC2]\n",
    "Mod = [str(x).lower() for x in Mod]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Class of CompositeDisease the occurence of a term of DiseaseClass or SpecificDisease followed by another will be used, with an instance of and, or or / \\ between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring and Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the requirements for an n-gram upper limit, we take a look at our keyword element distributions.\n",
    "At the same time we will remove stopwords, punctuation and digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({3: 5052, 4: 3769, 2: 3077, 5: 1561, 1: 564, 6: 263, 7: 38, 8: 4})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_DC1 = [len(element.split()) for element in DC1]  \n",
    "print(Counter(num_words_DC1))\n",
    "\n",
    "DC1_tidy = []\n",
    "DC1_cleaned=copy.deepcopy(DC1)\n",
    "for string in DC1_cleaned:\n",
    "    if string not in stopwords:\n",
    "        DC1_tidy.append(string.translate(str.maketrans('', '', punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({2: 21, 3: 13, 1: 2, 4: 1})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_DC2 = [len(element.split()) for element in DC2]  \n",
    "print(Counter(num_words_DC2))\n",
    "\n",
    "DC2_tidy = []\n",
    "DC2_cleaned=copy.deepcopy(DC2)\n",
    "for string in DC2_cleaned:\n",
    "    if string not in stopwords:\n",
    "        DC2_tidy.append(string.translate(str.maketrans('', '', punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({5: 1784, 4: 1722, 3: 1574, 6: 1334, 7: 1234, 2: 1169, 8: 1022, 9: 786, 10: 717, 11: 592, 12: 468, 1: 330, 13: 325, 14: 299, 15: 237, 16: 189, 17: 155, 18: 145, 19: 100, 21: 75, 20: 66, 22: 64, 24: 34, 23: 32, 26: 29, 27: 23, 25: 20, 29: 19, 30: 8, 28: 5, 32: 4, 31: 1})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD1 = [len(element.split()) for element in SD1]  \n",
    "print(Counter(num_words_SD1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({2: 3858, 3: 2902, 1: 2107, 4: 1533, 5: 822, 6: 362, 7: 254, 8: 113, 9: 45, 10: 32, 11: 19, 12: 6, 15: 1, 17: 1, 16: 1, 13: 1})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD3 = [len(element.split()) for element in SD3]  \n",
    "print(Counter(num_words_SD3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Pretty printing has been turned ON\n",
      "Counter({5: 1784, 4: 1722, 3: 1574, 6: 1334, 7: 1234, 2: 1169, 8: 1022, 9: 787, 10: 716, 11: 594, 12: 472, 1: 330, 13: 324, 14: 298, 15: 235, 16: 189, 17: 154, 18: 145, 19: 99, 21: 74, 20: 67, 22: 64, 24: 34, 23: 32, 26: 29, 27: 23, 25: 20, 29: 19, 30: 8, 28: 5, 32: 4, 31: 1})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD1 = [len(element.split()) for element in SD1]  \n",
    "#print(Counter(num_words_SD1))\n",
    "SD1_tidy = []\n",
    "SD1_cleaned=copy.deepcopy(SD1)\n",
    "for string in SD1_cleaned:\n",
    "    if string not in stopwords:\n",
    "        SD1_tidy.append(string.translate(str.maketrans('', '', punctuation)))\n",
    "\n",
    "%pprint\n",
    "num_words_SD1_tidy = [len(element.split()) for element in SD1_tidy]  \n",
    "print(Counter(num_words_SD1_tidy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({2: 3629, 3: 2782, 4: 2296, 5: 1373, 1: 1373, 6: 733, 7: 378, 8: 253, 9: 162, 10: 98, 11: 58, 12: 30, 13: 11, 14: 7, 15: 5, 19: 1, 16: 1})\n",
      "Counter({2: 3630, 3: 2781, 4: 2297, 5: 1375, 1: 1373, 6: 730, 7: 378, 8: 253, 9: 163, 10: 97, 11: 58, 12: 30, 13: 11, 14: 7, 15: 5, 19: 1, 16: 1})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD2 = [len(element.split()) for element in SD2]  \n",
    "print(Counter(num_words_SD2))\n",
    "\n",
    "SD2_tidy = []\n",
    "SD2_cleaned=copy.deepcopy(SD2)\n",
    "for string in SD2_cleaned:\n",
    "    if string not in stopwords:\n",
    "        SD2_tidy.append(string.translate(str.maketrans('', '', punctuation)))\n",
    "\n",
    "num_words_SD2_tidy = [len(element.split()) for element in SD2_tidy]  \n",
    "print(Counter(num_words_SD2_tidy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "Counter({2: 3859, 3: 2910, 1: 2104, 4: 1583, 5: 775, 6: 359, 7: 247, 8: 112, 9: 45, 10: 32, 11: 18, 12: 6, 15: 1, 17: 1, 16: 1, 13: 1})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_SD3 = [len(element.split()) for element in SD3]  \n",
    "#print(Counter(num_words_SD3))\n",
    "\n",
    "SD3_tidy = []\n",
    "SD3_cleaned=copy.deepcopy(SD3)\n",
    "for string in SD3_cleaned:\n",
    "    if string not in stopwords:\n",
    "        SD3_tidy.append(string.translate(str.maketrans('', '', punctuation)))\n",
    "\n",
    "num_words_SD3_tidy = [len(element.split()) for element in SD3_tidy]  \n",
    "print(Counter(num_words_SD3_tidy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "Counter({1: 1720})\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "num_words_Mod = [len(element.split()) for element in Mod]  \n",
    "print(Counter(num_words_Mod))\n",
    "\n",
    "Mod_tidy = []\n",
    "Mod_cleaned=copy.deepcopy(Mod)\n",
    "for string in Mod_cleaned:\n",
    "    if string not in stopwords:\n",
    "        Mod_tidy.append(string.translate(str.maketrans('', '', punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC1_trim = []\n",
    "for element in DC1_tidy:\n",
    "    element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "    DC1_trim.append(element)\n",
    "\n",
    "DC2_trim = []\n",
    "for element in DC2_tidy:\n",
    "    element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "    DC2_trim.append(element)\n",
    "\n",
    "SD1_trim = []\n",
    "for element in SD1_tidy:\n",
    "    element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "    SD1_trim.append(element)\n",
    "\n",
    "SD2_trim = []\n",
    "for element in SD2_tidy:\n",
    "    element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "    SD2_trim.append(element)\n",
    "\n",
    "SD3_trim = []\n",
    "for element in SD3_tidy:\n",
    "    element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "    SD3_trim.append(element)\n",
    "\n",
    "Mod_trim = []\n",
    "for element in Mod_tidy:\n",
    "    element=result = ''.join([i for i in element if not i.isdigit()])\n",
    "    Mod_trim.append(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sensible cutoff point where most of our keywords are retained for rules is going to be 7_grams. In the nextstep, the lists will be ridded of any elements with more terms within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC1_groomed = []\n",
    "for element in DC1_trim:\n",
    "    if len(element.split()) < 3:\n",
    "        DC1_groomed.append(element)\n",
    "\n",
    "DC2_groomed = []\n",
    "for element in DC2_trim:\n",
    "    if len(element.split()) < 3:\n",
    "        DC2_groomed.append(element)\n",
    "\n",
    "SD1_groomed = []\n",
    "for element in SD1_trim:\n",
    "    if len(element.split()) < 3:\n",
    "        SD1_groomed.append(element)\n",
    "\n",
    "SD2_groomed = []\n",
    "for element in SD2_trim:\n",
    "    if len(element.split()) < 3:\n",
    "        SD2_groomed.append(element)\n",
    "\n",
    "SD3_groomed = []\n",
    "for element in SD3_trim:\n",
    "    if len(element.split()) < 3:\n",
    "        SD3_groomed.append(element)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to mittigate the problems of the excessive RAM usage, we will be sampling the dataset heavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_notes = pd.read_csv('../../../mimic-iii-clinical-database-1.4/NOTEEVENTS.csv', low_memory=False)\n",
    "# df_notes = df_notes.sample(frac=0.01, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# notes_text = df_notes.TEXT\n",
    "# notes_text = notes_text.str.replace(r'\\[\\*\\*(.*?)\\*\\*\\]', '') # extract tag placeholders\n",
    "# notes_text = notes_text.str.replace(r'[0-9]+', '') # extract all digits\n",
    "# punctuation = string.punctuation.replace('/', '')\n",
    "# punctuation = punctuation.replace('\\\\', '') # excluding slashes from punctuation removal, since we need them to match with some disease\n",
    "\n",
    "# notes_text = notes_text.str.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "# stopwords = stopwords.words('english')\n",
    "# stopwords.remove('and')\n",
    "# stopwords.remove('or')\n",
    "# notes_text = notes_text.apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes_text.to_csv('../data/notes_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our lists as well as the traing data are looking dapper and shiny, we will wrap them up with a bow and store them for later use, and in order to ease collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    os.remove(\\'DC1.txt\\')\\nexcept OSError:\\n    pass\\n\\ntry:\\n    os.remove(\\'DC2.txt\\')\\nexcept OSError:\\n    pass\\n\\ntry:\\n    os.remove(\\'SD1.txt\\')\\nexcept OSError:\\n    pass\\n\\ntry:\\n    os.remove(\\'SD2.txt\\')\\nexcept OSError:\\n    pass\\n\\ntry:\\n    os.remove(\\'SD3.txt\\')\\nexcept OSError:\\n    pass\\n\\ntry:\\n    os.remove(\\'Mod.txt\\')\\nexcept OSError:\\n    pass\\n\\nwith open(r\\'DC1.txt\\', \\'w\\') as fp:\\n    for item in DC1_groomed:\\n        #writes each entry on a new line\\n        fp.write(\"%s\\n\" % item)\\n    print(\\'Done\\')\\n\\nwith open(r\\'DC2.txt\\', \\'w\\') as fp:\\n    for item in DC2_groomed:\\n        fp.write(\"%s\\n\" % item)\\n    print(\\'Done\\')\\n\\nwith open(r\\'SD1.txt\\', \\'w\\') as fp:\\n    for item in SD1_groomed:\\n        fp.write(\"%s\\n\" % item)\\n    print(\\'Done\\')\\n\\n\\nwith open(r\\'SD2.txt\\', \\'w\\') as fp:\\n    for item in SD2_groomed:\\n        fp.write(\"%s\\n\" % item)\\n    print(\\'Done\\')\\n    \\n\\nwith open(r\\'SD3.txt\\', \\'w\\') as fp:\\n    for item in SD3_groomed:\\n        fp.write(\"%s\\n\" % item)\\n    print(\\'Done\\')\\n\\n\\nwith open(r\\'Mod.txt\\', \\'w\\') as fp:\\n    for item in Mod_trim:\\n        fp.write(\"%s\\n\" % item)\\n    print(\\'Done\\')\\n\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "try:\n",
    "    os.remove('DC1.txt')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove('DC2.txt')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove('SD1.txt')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove('SD2.txt')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove('SD3.txt')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove('Mod.txt')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "with open(r'./data/DC1.txt', 'w') as fp:\n",
    "    for item in DC1_groomed:\n",
    "        #writes each entry on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "with open(r'./data/DC2.txt', 'w') as fp:\n",
    "    for item in DC2_groomed:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "with open(r'./data/SD1.txt', 'w') as fp:\n",
    "    for item in SD1_groomed:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "with open(r'./data/SD2.txt', 'w') as fp:\n",
    "    for item in SD2_groomed:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "    \n",
    "\n",
    "with open(r'./data/SD3.txt', 'w') as fp:\n",
    "    for item in SD3_groomed:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "with open(r'./data/Mod.txt', 'w') as fp:\n",
    "    for item in Mod_trim:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the preprocessing of the test and dev data - NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_t = []\n",
    "labels_t = []\n",
    "\n",
    "file = open('./data/NCBItestset_corpus.txt', 'r')\n",
    "Lines = file.readlines()\n",
    "  \n",
    "for line in Lines:\n",
    "    if line.find(\"|\") > 0:\n",
    "        text_t.append(line)\n",
    "    elif len(line) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        labels_t.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_d = []\n",
    "labels_d = []\n",
    "\n",
    "file = open('./data/NCBIdevelopset_corpus.txt', 'r')\n",
    "Lines = file.readlines()\n",
    "  \n",
    "for line in Lines:\n",
    "    if line.find(\"|\") > 0:\n",
    "        text_d.append(line)\n",
    "    elif len(line) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        labels_d.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.DataFrame([elem.split(\"|\") for elem in text_t])\n",
    "test_text.drop(test_text.columns[[1,3]],axis=1, inplace=True)\n",
    "test_text.columns = ['ID','Text']\n",
    "test_text[test_text.columns[0]] = test_text[test_text.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "test_text_f = test_text[test_text['ID'] == 0].index\n",
    "test_text.drop(test_text_f, inplace=True)\n",
    "test_text = test_text.groupby(['ID']).agg({'Text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_text = pd.DataFrame([elem.split(\"|\") for elem in text_d])\n",
    "dev_text.drop(dev_text.columns[[1,3]],axis=1, inplace=True)\n",
    "dev_text.columns = ['ID','Text']\n",
    "dev_text[dev_text.columns[0]] = dev_text[dev_text.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "dev_text_f = dev_text[dev_text['ID'] == 0].index\n",
    "dev_text.drop(dev_text_f, inplace=True)\n",
    "dev_text = dev_text.groupby(['ID']).agg({'Text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = pd.DataFrame([elem.split('\\t') for elem in labels_t])\n",
    "test_label.drop(test_label.columns[[1,2,5]],axis=1, inplace=True)\n",
    "test_label.columns =['ID', 'Label', 'Class']\n",
    "test_label[test_label.columns[0]] = test_label[test_label.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "test_label_f = test_label[test_label['ID'] == 0].index\n",
    "test_label.drop(test_label_f, inplace=True)\n",
    "test_label = test_label[test_label['Label'].str.count(' ') == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label = pd.DataFrame([elem.split('\\t') for elem in labels_d])\n",
    "dev_label.drop(dev_label.columns[[1,2,5]],axis=1, inplace=True)\n",
    "dev_label.columns =['ID', 'Label', 'Class']\n",
    "dev_label[dev_label.columns[0]] = dev_label[dev_label.columns[0]].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).dropna()\n",
    "dev_label_f = dev_label[dev_label['ID'] == 0].index\n",
    "dev_label.drop(dev_label_f, inplace=True)\n",
    "dev_label = dev_label[dev_label['Label'].str.count(' ') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "for char in punctuation:\n",
    "    test_label['Label'] = test_label['Label'].str.replace(char, '')\n",
    "       \n",
    "for char in digits:\n",
    "    test_label['Label'] = test_label['Label'].str.replace(char, '')\n",
    "    \n",
    "for char in punctuation:\n",
    "    test_text['Text'] = test_text['Text'].str.replace(char, '')\n",
    "\n",
    "for char in digits:\n",
    "    test_text['Text'] = test_text['Text'].str.replace(char, '')\n",
    "\n",
    "test_text[\"Text\"] = test_text[\"Text\"].str.lower()\n",
    "test_label[\"Label\"] = test_label[\"Label\"].str.lower()\n",
    "test_text[\"Text\"] = test_text[\"Text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/florian/.pyenv/versions/3.7.15/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "for char in punctuation:\n",
    "    dev_label['Label'] = dev_label['Label'].str.replace(char, '')\n",
    "       \n",
    "for char in digits:\n",
    "    dev_label['Label'] = dev_label['Label'].str.replace(char, '')\n",
    "    \n",
    "for char in punctuation:\n",
    "    dev_text['Text'] = dev_text['Text'].str.replace(char, '')\n",
    "\n",
    "for char in digits:\n",
    "    dev_text['Text'] = dev_text['Text'].str.replace(char, '')\n",
    "\n",
    "dev_text[\"Text\"] = dev_text[\"Text\"].str.lower()\n",
    "dev_label[\"Label\"] = dev_label[\"Label\"].str.lower()\n",
    "dev_text[\"Text\"] = dev_text[\"Text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8755645</td>\n",
       "      <td>fed</td>\n",
       "      <td>SpecificDisease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8755645</td>\n",
       "      <td>fed</td>\n",
       "      <td>SpecificDisease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8674108</td>\n",
       "      <td>tumors</td>\n",
       "      <td>DiseaseClass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8917548</td>\n",
       "      <td>ataxiatelangiectasia</td>\n",
       "      <td>SpecificDisease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8917548</td>\n",
       "      <td>thymomas</td>\n",
       "      <td>SpecificDisease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                 Label            Class\n",
       "18  8755645                   fed  SpecificDisease\n",
       "20  8755645                   fed  SpecificDisease\n",
       "34  8674108                tumors     DiseaseClass\n",
       "43  8917548  ataxiatelangiectasia  SpecificDisease\n",
       "44  8917548              thymomas  SpecificDisease"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>hereditary deficiency fifth component compleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941901</th>\n",
       "      <td>low levels beta hexosaminidase healthy individ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993342</th>\n",
       "      <td>chromosomal order genes controlling major hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288106</th>\n",
       "      <td>clustering missense mutations ataxiatelangiect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294109</th>\n",
       "      <td>myotonic dystrophy protein kinase involved mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Text\n",
       "ID                                                        \n",
       "932197   hereditary deficiency fifth component compleme...\n",
       "941901   low levels beta hexosaminidase healthy individ...\n",
       "993342   chromosomal order genes controlling major hist...\n",
       "9288106  clustering missense mutations ataxiatelangiect...\n",
       "9294109  myotonic dystrophy protein kinase involved mod..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text['Terms'] = test_text['Text'].str.split(' ')\n",
    "test_word=test_text.explode('Terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>brca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>secreted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>exhibits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589722</th>\n",
       "      <td>granin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Terms\n",
       "ID                 \n",
       "8589722        brca\n",
       "8589722    secreted\n",
       "8589722    exhibits\n",
       "8589722  properties\n",
       "8589722      granin"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_text['Terms'] = dev_text['Text'].str.split(' ')\n",
    "dev_word=dev_text.explode('Terms')\n",
    "dev_word.drop('Text', axis=1, inplace=True)\n",
    "dev_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>hereditary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>fifth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932197</th>\n",
       "      <td>complement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Terms\n",
       "ID                \n",
       "932197  hereditary\n",
       "932197  deficiency\n",
       "932197       fifth\n",
       "932197   component\n",
       "932197  complement"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word.drop('Text', axis=1, inplace=True)\n",
    "test_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_fin=test_word.merge(test_label, left_on=['ID','Terms'], right_on = ['ID','Label'], how='left')\n",
    "Test_fin.drop('Label', axis=1, inplace=True)\n",
    "Test_fin.fillna('OTHER', axis=1, inplace=True)\n",
    "Test_fin_f = Test_fin[Test_fin['Class'] == 'Modifier'].index\n",
    "Test_fin.drop(Test_fin_f, inplace=True)\n",
    "Test_fin_f = Test_fin[Test_fin['Class'] == 'CompositeMention'].index\n",
    "Test_fin.drop(Test_fin_f, inplace=True)\n",
    "Test_fin=Test_fin[Test_fin.ID != 9472666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dev_fin=dev_word.merge(dev_label, left_on=['ID','Terms'], right_on = ['ID','Label'], how='left')\n",
    "Dev_fin.drop('Label', axis=1, inplace=True)\n",
    "Dev_fin.fillna('OTHER', axis=1, inplace=True)\n",
    "Dev_fin_f = Dev_fin[Dev_fin['Class'] == 'Modifier'].index\n",
    "Dev_fin.drop(Dev_fin_f, inplace=True)\n",
    "Dev_fin_f = Dev_fin[Dev_fin['Class'] == 'CompositeMention'].index\n",
    "Dev_fin.drop(Dev_fin_f, inplace=True)\n",
    "Dev_fin.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_fin.to_csv('./data/test_fin.csv', index=False)\n",
    "\n",
    "Dev_fin.to_csv('./data/dev_fin.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit ('3.7.15')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66d5c63fb80eb6fd04af604839a1d74609fa54c5a8a540ddfe18aa77248ed3d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
