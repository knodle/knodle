{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ae4296",
   "metadata": {},
   "source": [
    "# Obtain contextual embeddings of sentences containing 2 NEs each\n",
    "\n",
    "In this Jupyter-notebook, contextualised embeddings are obtained of sentences with 2 NEs tagged, which will be further used for temporal relation extraction. This approach builds on Zhou et al. (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a88ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from joblib import load, dump \n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import transformers\n",
    "from sklearn.metrics import *\n",
    "from transformers import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForSequenceClassification, AutoModel, BertModel, BertConfig, AutoConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194cffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14346a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file:\n",
    "# with open('./test_data.joblib', 'rb') as f:    # embeddings test data\n",
    "with open('./ast_ann_sent.joblib', 'rb') as f:    # embeddings training data\n",
    "    ast_ann_sent = load(f)\n",
    "data_ast = pd.DataFrame(ast_ann_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32cdf7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SENT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date *2151-7-16* discharge date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 *discharge* date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 discharge date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                            SENT\n",
       "  note_id sent_id                                                                                                                                                                                                                                               \n",
       "0 0       0         admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis \n",
       "2 0       0         admission date *2151-7-16* discharge date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis* \n",
       "3 0       0         admission date 2151-7-16 *discharge* date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis \n",
       "4 0       0         admission date 2151-7-16 *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis* \n",
       "5 0       0         admission date 2151-7-16 discharge date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis* "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b3e1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a BERT tokenizer based on WordPiece\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d770a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 9634, 3058, 1008, 17405, 2487, 1011, 1021, 1011, 2385, 1008, 1008, 11889, 1008, 3058, 17405, 2487, 1011, 1022, 1011, 1018, 2326, 5587, 10497, 2819, 2557, 27179, 2913, 2557, 27179, 2913, 2036, 2443, 1037, 3108, 14931, 2029, 4484, 6187, 28403, 2854, 22520, 1999, 1996, 2187, 11192, 13450, 8335, 2007, 16514, 2832, 15877, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# A sanity check of the tokenizer\n",
    "encoded_instance = bert_tokenizer.batch_encode_plus([data_ast.iloc[0].SENT], padding=True)\n",
    "print(encoded_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f315657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis \n",
      "BERT BPEs: ['[CLS]', 'admission', 'date', '*', '215', '##1', '-', '7', '-', '16', '*', '*', 'discharge', '*', 'date', '215', '##1', '-', '8', '-', '4', 'service', 'add', '##end', '##um', 'radio', '##logic', 'studies', 'radio', '##logic', 'studies', 'also', 'included', 'a', 'chest', 'ct', 'which', 'confirmed', 'ca', '##vita', '##ry', 'lesions', 'in', 'the', 'left', 'lung', 'apex', 'consistent', 'with', 'infectious', 'process', 'tuberculosis', '[SEP]']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", data_ast.iloc[0].SENT)\n",
    "print(\"BERT BPEs:\", bert_tokenizer.convert_ids_to_tokens(encoded_instance[\"input_ids\"][0]))\n",
    "a = bert_tokenizer.batch_encode_plus([data_ast.iloc[0].SENT], padding=True)\n",
    "tokens = bert_tokenizer.convert_ids_to_tokens(encoded_instance[\"input_ids\"][0])\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffca064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 19, 19, 20, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, None]\n"
     ]
    }
   ],
   "source": [
    "print(a.word_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb7fdb",
   "metadata": {},
   "source": [
    "Comment: in this case, it is not adequate to use .word_ids() to refer to the index of the whitespace of the entity before bert_tokenizer, as the .word_ids()-index does not always refer to words separated by a whitespace. In the upper example, the date (1 NE) has 5 different word_ids. Therefore I used the following approach: bert_tokenize the sentences (including 4 '\\*' separating the 2 NE) to get the entity positions. In a second step, remove the '\\*' from the sentences to tokenize the data NOT including the '\\*' to generate the embeddings of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6466d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only sentences with two NE marked with an * --> just to be sure that there are only sentences with 2 NEs tagged in the data\n",
    "\n",
    "def only_2NE(x):\n",
    "    result = None\n",
    "    numb_ne = x.split('*')\n",
    "    if len(numb_ne) == 5:\n",
    "        result = x\n",
    "    return result\n",
    "\n",
    "data_ast.SENT = data_ast.SENT.apply(lambda x: only_2NE(x))\n",
    "\n",
    "\n",
    "not_2NE = (data_ast.SENT.isna())\n",
    "data_ast = data_ast[~not_2NE]\n",
    "len(data_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b0a7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the positions of the named entities\n",
    "\n",
    "ent_pos_df = data_ast.copy()\n",
    "\n",
    "def get_embeddings(x):\n",
    "    z = 0\n",
    "    y = 0\n",
    "    encoded_instance = bert_tokenizer.batch_encode_plus([x], padding=True)\n",
    "    sent = bert_tokenizer.convert_ids_to_tokens(encoded_instance[\"input_ids\"][0])\n",
    "    entity_pos = []\n",
    "    indices = []\n",
    "    ent1, ent2 = [], []\n",
    "    for t in sent:\n",
    "        # first find all four '*'\n",
    "        if re.match('\\*', t):\n",
    "            indices.append(z-y)\n",
    "            y +=1\n",
    "        z+=1\n",
    "    if len(indices)==4:\n",
    "        ent1 = indices[:2] # index / indices of the first NE\n",
    "        ent2 = indices[2:] # index / indices of the second NE\n",
    "    entity_pos.append(ent1)\n",
    "    entity_pos.append(ent2)\n",
    "    if len(ent1) != 2 or len(ent2) != 2:\n",
    "        entity_pos = None\n",
    "    return entity_pos  \n",
    "\n",
    "ent_pos_df['embeddings'] = data_ast.SENT.apply(lambda x: get_embeddings(x))\n",
    "\n",
    "#def get_tok(x):\n",
    "#    encoded_instance = bert_tokenizer.batch_encode_plus([x], padding=True)\n",
    "#    sent = bert_tokenizer.convert_ids_to_tokens(encoded_instance[\"input_ids\"][0])\n",
    "#    return sent\n",
    "\n",
    "#ent_pos_df.SENT = data_ast.SENT.apply(lambda x: get_tok(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b00d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SENT</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis</td>\n",
       "      <td>[[3, 9], [9, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date *2151-7-16* discharge date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "      <td>[[3, 9], [47, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 *discharge* date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis</td>\n",
       "      <td>[[9, 10], [11, 17]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "      <td>[[9, 10], [47, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 discharge date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "      <td>[[11, 17], [47, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>*two days* prior to *admission* she was started on a prednisone taper and one day prior to admission she required oxygen at home in order to maintain oxygen saturation greater than 90</td>\n",
       "      <td>[[1, 3], [5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>two days prior to admission she was started on a prednisone taper and *one day* prior to *admission* she required oxygen at home in order to maintain oxygen saturation greater than 90</td>\n",
       "      <td>[[18, 20], [22, 23]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>review of systems is negative for the following *fevers* *chills* nausea vomiting night sweats change in weight gastrointestinal complaints neurologic changes rashes palpitations orthopnea</td>\n",
       "      <td>[[9, 11], [11, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>review of systems is negative for the following *fevers* chills *nausea* vomiting night sweats change in weight gastrointestinal complaints neurologic changes rashes palpitations orthopnea</td>\n",
       "      <td>[[9, 11], [13, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>review of systems is negative for the following *fevers* chills nausea *vomiting* night sweats change in weight gastrointestinal complaints neurologic changes rashes palpitations orthopnea</td>\n",
       "      <td>[[9, 11], [14, 15]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                             SENT  \\\n",
       "   note_id sent_id                                                                                                                                                                                                                                                  \n",
       "0  0       0         admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis    \n",
       "2  0       0         admission date *2151-7-16* discharge date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*    \n",
       "3  0       0         admission date 2151-7-16 *discharge* date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis    \n",
       "4  0       0         admission date 2151-7-16 *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*    \n",
       "5  0       0         admission date 2151-7-16 discharge date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*    \n",
       "16 1       1                                                             *two days* prior to *admission* she was started on a prednisone taper and one day prior to admission she required oxygen at home in order to maintain oxygen saturation greater than 90    \n",
       "21 1       1                                                             two days prior to admission she was started on a prednisone taper and *one day* prior to *admission* she required oxygen at home in order to maintain oxygen saturation greater than 90    \n",
       "22 1       5                                                        review of systems is negative for the following *fevers* *chills* nausea vomiting night sweats change in weight gastrointestinal complaints neurologic changes rashes palpitations orthopnea    \n",
       "23 1       5                                                        review of systems is negative for the following *fevers* chills *nausea* vomiting night sweats change in weight gastrointestinal complaints neurologic changes rashes palpitations orthopnea    \n",
       "24 1       5                                                        review of systems is negative for the following *fevers* chills nausea *vomiting* night sweats change in weight gastrointestinal complaints neurologic changes rashes palpitations orthopnea    \n",
       "\n",
       "                              embeddings  \n",
       "   note_id sent_id                        \n",
       "0  0       0           [[3, 9], [9, 10]]  \n",
       "2  0       0          [[3, 9], [47, 48]]  \n",
       "3  0       0         [[9, 10], [11, 17]]  \n",
       "4  0       0         [[9, 10], [47, 48]]  \n",
       "5  0       0        [[11, 17], [47, 48]]  \n",
       "16 1       1            [[1, 3], [5, 6]]  \n",
       "21 1       1        [[18, 20], [22, 23]]  \n",
       "22 1       5         [[9, 11], [11, 13]]  \n",
       "23 1       5         [[9, 11], [13, 14]]  \n",
       "24 1       5         [[9, 11], [14, 15]]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_pos = ent_pos_df.embeddings.values.tolist()\n",
    "ent_pos_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71ec3997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SENT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date *2151-7-16* discharge date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 *discharge* date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2151-7-16 discharge date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                            SENT\n",
       "  note_id sent_id                                                                                                                                                                                                                                               \n",
       "0 0       0         admission date *2151-7-16* *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis \n",
       "2 0       0         admission date *2151-7-16* discharge date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis* \n",
       "3 0       0         admission date 2151-7-16 *discharge* date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process tuberculosis \n",
       "4 0       0         admission date 2151-7-16 *discharge* date 2151-8-4 service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis* \n",
       "5 0       0         admission date 2151-7-16 discharge date *2151-8-4* service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process *tuberculosis* "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cde90029",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_ast.copy()\n",
    "data.SENT = data.SENT.apply(lambda x: x.replace('*', ''))\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9730339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum sentence length in the data based on BERT BPEs is 89\n"
     ]
    }
   ],
   "source": [
    "# Set max_len to the maximum length of the training data \n",
    "max_len = max([len(bert_tokenizer.encode(s)) for s in data.SENT.to_list()])\n",
    "print(\"The maximum sentence length in the data based on BERT BPEs is\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c789dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the sentences\n",
    "embed = bert_tokenizer.batch_encode_plus(\n",
    "    data.SENT.tolist(),\n",
    "    max_length = max_len,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9170ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to tensors \n",
    "embed_seq = torch.tensor(embed['input_ids'])\n",
    "embed_mask = torch.tensor(embed['attention_mask'])\n",
    "embed_ent_pos = torch.tensor(entity_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99c33708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  9],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_ent_pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abe010f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6791de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3704, 89])\n",
      "torch.Size([3704, 89])\n",
      "torch.Size([3704, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(embed_seq.size())\n",
    "print(embed_mask.size())\n",
    "print(embed_ent_pos.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "142e22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# Create a dataloader for each set\n",
    "# TensorDataset: Creates a PyTorch dataset object to load data from\n",
    "embed_data = TensorDataset(embed_seq, embed_mask, embed_ent_pos)\n",
    "\n",
    "# DataLoader: a Python iterable over a dataset\n",
    "embed_dataloader = DataLoader(embed_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(len(embed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42aeeb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5ee32e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed468836eec4f57beb5e68cf697fcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n",
      "torch.Size([4, 89, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1093632 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1684\\1416633519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msent_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ment_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Tensor (batch_size x input_length x 768)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m         )\n\u001b[0;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m                 )\n\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         )\n\u001b[0;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m             \u001b[0mkey_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_project\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1093632 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "# all entity embeddings\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(embed_dataloader, desc=\"Iteration\"):  \n",
    "    batch = [r.to(device) for r in batch] \n",
    "    sent_id, mask, ent_pos = batch\n",
    "    output = model(sent_id, attention_mask=mask)\n",
    "    sequence_output = output[0]  # Tensor (batch_size x input_length x 768)\n",
    "    for i in range(len(batch)):          # for each instance = sentence\n",
    "        entity_embs = []   # entity embeddings for each sentence\n",
    "        entries = ent_pos[i].tolist()\n",
    "        # 2 entries per scentence\n",
    "        for start, end in entries:        # for start and end position of each mention\n",
    "            for y in range(start,end):\n",
    "                entity_embs.append(sequence_output[i, y + 1])\n",
    "        if len(entity_embs) > 0:\n",
    "            entity_embs = torch.logsumexp(torch.stack(entity_embs, dim=0), dim=0)\n",
    "        else:                                                           # should not be the case\n",
    "            entity_embs = torch.zeros(self.hidden_size).to(sequence_output)\n",
    "        all_embeddings.append(entity_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24424f9f",
   "metadata": {},
   "source": [
    "train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f772a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings = all_embeddings \n",
    "len(train_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05980e9f",
   "metadata": {},
   "source": [
    "Due to a runtime error, only a part of the embeddings is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf8f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file4 = './train_embeddings_540.joblib'\n",
    "with open(pickle_file4, 'wb') as f:\n",
    "    dump(train_embeddings, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80453dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = joblib.load('./train_embeddings_540.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b1bbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_tens = []\n",
    "for t in train_embeddings:\n",
    "    a =t.detach()\n",
    "    train_emb_tens.append(a.tolist())\n",
    "\n",
    "train_emb_torch = torch.tensor(train_emb_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dba9a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([540, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f79142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokenized sentences in joblib format\n",
    "\n",
    "pickle_file5 = './train_embeddings_torch_540.joblib'\n",
    "with open(pickle_file5, 'wb') as f:\n",
    "    dump(train_emb_torch, f, compress='zlib')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d0446",
   "metadata": {},
   "source": [
    "test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970989e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = all_embeddings \n",
    "len(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12398e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb_tens = []\n",
    "for t in test_embeddings:\n",
    "    a =t.detach()\n",
    "    test_emb_tens.append(a.tolist())\n",
    "\n",
    "test_emb_torch = torch.tensor(test_emb_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1376b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87edccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokenized sentences in joblib format\n",
    "\n",
    "pickle_file6 = './test_embeddings.joblib'\n",
    "with open(pickle_file6, 'wb') as f:\n",
    "    dump(test_emb_torch, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814a43a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Zhou, W., Huang, K., Ma, T., & Huang, J. (2021, May). Document-level relation extraction with adaptive thresholding and localized context pooling. In Proceedings of the AAAI conference on artificial intelligence (Vol. 35, No. 16, pp. 14612-14620)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
