{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task 2 Data Wrangling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MIMIC III</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the MIMIC III dataset, which will function as our training/development dataset. Before we can use the data for building our weak supervision models we still have to do some preprocessing of certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes = pd.read_csv('./data/train/mimic-iii-clinical-database-1.4/NOTEEVENTS.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2083180, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
       "0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
       "1     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
       "2     176       13702  167118.0  2119-05-25       NaN       NaN   \n",
       "3     177       13702  196489.0  2124-08-18       NaN       NaN   \n",
       "4     178       26880  135453.0  2162-03-25       NaN       NaN   \n",
       "\n",
       "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0  Discharge summary      Report   NaN      NaN   \n",
       "1  Discharge summary      Report   NaN      NaN   \n",
       "2  Discharge summary      Report   NaN      NaN   \n",
       "3  Discharge summary      Report   NaN      NaN   \n",
       "4  Discharge summary      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_text = df_notes.TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_notes # removing variables from memory for tidying up RAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "notes_text = notes_text.str.replace(r'\\[\\*\\*(.*?)\\*\\*\\]', '') # extract tag placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "notes_text = notes_text.str.replace(r'[0-9]+', '') # extract all digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation.replace('/', '')\n",
    "punctuation = punctuation.replace('\\\\', '') # excluding slashes from punctuation removal, since we need them to match with some disease\n",
    "\n",
    "notes_text = notes_text.str.translate(str.maketrans('', '', punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stopwords.remove('and')\n",
    "stopwords.remove('or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_text = notes_text.apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_text.to_csv('./data/train/notes_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del notes_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_text = pd.read_csv('./data/train/notes_cleaned.csv', low_memory=False, chunksize = 10000, index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feeding the MIMIC III data to our labeling functions we opted for a n-gram approach - i. e. every note entry is split into x n-grams corresponding to x number of rows. Given the dimensions of our keyword lists we decided to generate every possible iteration from unigrams to 7-grams in order to then apply our labeling functions to every subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing ngrams in chunks for performance reasons\n",
    "\n",
    "def get_ngrams(file_path, n, df):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    for subset in df:\n",
    "        subset = subset.dropna()\n",
    "        subset['ngrams'] = subset['TEXT'].str.split().apply(lambda x: list(map(' '.join, ngrams(x, n=n))))\n",
    "        subset = (subset.assign(count=subset['ngrams'].str.len())\n",
    "    .explode('ngrams')\n",
    "    .query('count > 0'))\n",
    "        subset['index_notes'] = subset.index\n",
    "        subset = subset.drop(['count', 'TEXT'], axis=1)\n",
    "        if not os.path.isfile(file_path):\n",
    "            subset.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            subset.to_csv(file_path, index=False, mode='a', header=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/1grams.csv', 1, notes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/2grams.csv', 2, notes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/3grams.csv', 3, notes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/4grams.csv', 4, notes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/5grams.csv', 5, notes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/6grams.csv', 6, notes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams('./data/train/ngrams/7grams.csv', 7, notes_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Labeling Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step we load a text file containing a list of the most important clinical departments for our first labeling function. This list was scraped from different sources, which are also provided in the text file. The input from the text file is then transformed into a list, consisting of various ngrams, with each ngram denoting a clinical department. This list will then be applied to our ngrams from the MIMIC dataset where every exact match gets assigned the label \"DEP\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Department of Admissions': ['Admission',\n",
       "  'Admissions',\n",
       "  'Admitting Department'],\n",
       " 'Department of Anaesthesia, Intensive Care Medicine and Pain Medicine': ['Anesthetics',\n",
       "  'Anesthesiology'],\n",
       " 'Department of Blood Group Serology and Transfusion Medicine': ['Serology',\n",
       "  'Transfusion Medicine'],\n",
       " 'Department of Cardiac Surgery': ['Cardiology'],\n",
       " 'Department of Clinical Pathology': ['Clinical Pathology',\n",
       "  'Medical Laboratory'],\n",
       " 'Department of Dermatology': ['Dermatology'],\n",
       " 'Department of Ear, Nose and Throat Diseases': ['Otolaryngology',\n",
       "  'ENT Department',\n",
       "  'Ear',\n",
       "  'Nose and Throat Diseases'],\n",
       " 'Department of Emergency Medicine': ['Accident and emergency',\n",
       "  'A&E',\n",
       "  'Casualty Department'],\n",
       " 'Department of Gastroenterology': ['Gastroenterology'],\n",
       " 'Department of General Surgery': ['General Surgery', 'Surgery'],\n",
       " 'Department of Geriatry': ['Geriatric Department', 'Geriatrics'],\n",
       " 'Department of Haematology': ['Haematology'],\n",
       " 'Department of Hospital Hygiene and Infection Control': ['Central Sterile Services Department',\n",
       "  'CSSD',\n",
       "  'Sterile Processing Department',\n",
       "  'SPD',\n",
       "  'Sterile Processing',\n",
       "  'Infection Control'],\n",
       " 'Department of Medicine': ['Pharmacy', 'Medicine Department'],\n",
       " 'Department of Neurology': ['Neurology'],\n",
       " 'Department of Nursing': ['Nursing Department'],\n",
       " 'Department of Nutrition and Dietetics': ['Nutrition Department',\n",
       "  'Dietetics'],\n",
       " 'Department of Obstetrics and Gynaecology': ['Gynaecology',\n",
       "  'Gynecology',\n",
       "  'Obstetrics'],\n",
       " 'Department of Ophthalmology and Optometry': ['Ophthalmology', 'Optometry'],\n",
       " 'Department of Oral and Maxillofacial Surgery': ['Oral Surgery',\n",
       "  'Maxillofacial Surgery'],\n",
       " 'Department of Orthopedics': ['Orthopedics', 'Orthopaedics'],\n",
       " 'Department of Pediatrics': ['Pediatrics', 'Paediatrics'],\n",
       " 'Department of Plastic, Reconstructive and Aesthetic Surgery': ['Plastic Surgery Department',\n",
       "  'Aesthetic Surgery Department',\n",
       "  'Reconstructive Surgery Department'],\n",
       " 'Department of Physical Medicine, Rehabilitation and Occupational Medicine': ['Physiotherapy',\n",
       "  'Rehab',\n",
       "  'Rehabilitation Department'],\n",
       " 'Department of Psychiatry': ['Psychiatry'],\n",
       " 'Department of Psychoanalysis and Psychotherapy': ['Psychotherapy',\n",
       "  'Psychoanalysis'],\n",
       " 'Department of Radiation Oncology': ['X-Ray Department',\n",
       "  'Diagnostic Imaging',\n",
       "  'Oncology',\n",
       "  'Radiology',\n",
       "  'Oncology'],\n",
       " 'Department of Thoracic Surgery': ['Thoracic Surgery Department'],\n",
       " 'Department of Urology': ['Urology'],\n",
       " 'Clinic of Dentistry': ['Dentistry'],\n",
       " 'Critical Care': ['Critical Care',\n",
       "  'Intensive Care',\n",
       "  'Intensive Care Unit',\n",
       "  'ICU',\n",
       "  'Critical Care Unit',\n",
       "  'CCU',\n",
       "  'Intensive Treatment Unit',\n",
       "  'ITU',\n",
       "  'Intensive Therapy Unit'],\n",
       " 'Operating Theatre': ['Operating Theatre',\n",
       "  'OT',\n",
       "  'Operating Room',\n",
       "  'Operating Suite',\n",
       "  'Operation Suite'],\n",
       " 'Inpatient Department': ['IPD', 'Inpatient Department'],\n",
       " 'Outpatient Department': ['OPD', 'Outpatient Department']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/keywords/departments_list.txt\") as dataFile:\n",
    "    departments = {}\n",
    "    for line in dataFile:\n",
    "        if line.strip() == '': # exclude unnecessary lines\n",
    "            break\n",
    "        else:\n",
    "            line = line.split(':')\n",
    "            key, value = line[0], line[1:]\n",
    "            value = [i.replace(';', ',') for i in value]\n",
    "            value = [i.split(',') for i in value]\n",
    "            [[value]] = [value]\n",
    "            value = [i.strip() for i in value]\n",
    "            departments[key] = value\n",
    "\n",
    "departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments_keywords = list(departments.values())\n",
    "departments_keywords = [item.lower() for sublist in departments_keywords for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admission',\n",
       " 'admissions',\n",
       " 'admitting department',\n",
       " 'anesthetics',\n",
       " 'anesthesiology',\n",
       " 'serology',\n",
       " 'transfusion medicine',\n",
       " 'cardiology',\n",
       " 'clinical pathology',\n",
       " 'medical laboratory',\n",
       " 'dermatology',\n",
       " 'otolaryngology',\n",
       " 'ent department',\n",
       " 'ear',\n",
       " 'nose and throat diseases',\n",
       " 'accident and emergency',\n",
       " 'a&e',\n",
       " 'casualty department',\n",
       " 'gastroenterology',\n",
       " 'general surgery',\n",
       " 'surgery',\n",
       " 'geriatric department',\n",
       " 'geriatrics',\n",
       " 'haematology',\n",
       " 'central sterile services department',\n",
       " 'cssd',\n",
       " 'sterile processing department',\n",
       " 'spd',\n",
       " 'sterile processing',\n",
       " 'infection control',\n",
       " 'pharmacy',\n",
       " 'medicine department',\n",
       " 'neurology',\n",
       " 'nursing department',\n",
       " 'nutrition department',\n",
       " 'dietetics',\n",
       " 'gynaecology',\n",
       " 'gynecology',\n",
       " 'obstetrics',\n",
       " 'ophthalmology',\n",
       " 'optometry',\n",
       " 'oral surgery',\n",
       " 'maxillofacial surgery',\n",
       " 'orthopedics',\n",
       " 'orthopaedics',\n",
       " 'pediatrics',\n",
       " 'paediatrics',\n",
       " 'plastic surgery department',\n",
       " 'aesthetic surgery department',\n",
       " 'reconstructive surgery department',\n",
       " 'physiotherapy',\n",
       " 'rehab',\n",
       " 'rehabilitation department',\n",
       " 'psychiatry',\n",
       " 'psychotherapy',\n",
       " 'psychoanalysis',\n",
       " 'x-ray department',\n",
       " 'diagnostic imaging',\n",
       " 'oncology',\n",
       " 'radiology',\n",
       " 'oncology',\n",
       " 'thoracic surgery department',\n",
       " 'urology',\n",
       " 'dentistry',\n",
       " 'critical care',\n",
       " 'intensive care',\n",
       " 'intensive care unit',\n",
       " 'icu',\n",
       " 'critical care unit',\n",
       " 'ccu',\n",
       " 'intensive treatment unit',\n",
       " 'itu',\n",
       " 'intensive therapy unit',\n",
       " 'operating theatre',\n",
       " 'ot',\n",
       " 'operating room',\n",
       " 'operating suite',\n",
       " 'operation suite',\n",
       " 'ipd',\n",
       " 'inpatient department',\n",
       " 'opd',\n",
       " 'outpatient department']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departments_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting subset of ngrams from a given keyword list\n",
    "\n",
    "def ngrams_keywords(n, input_ls):\n",
    "    output_ls = []\n",
    "    for i in input_ls:\n",
    "        ws = i.count(' ')\n",
    "        if ws == n-1:\n",
    "            output_ls.append(i)\n",
    "    return output_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling function takes as input a dataframe, a label and a list of keywords and assigns for every exact match the label to a given row \n",
    "\n",
    "def labeling_function(file_path, label, df, keyword_list):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    for subset in df:\n",
    "        subset = subset.dropna()\n",
    "        subset = subset.drop_duplicates()\n",
    "        subset['label'] = subset['ngrams'].map(lambda x: label if x in keyword_list else 0)\n",
    "        subset = subset[subset.label != 0]\n",
    "        if not os.path.isfile(file_path):\n",
    "            subset.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            subset.to_csv(file_path, index=False, mode='a', header=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_ngrams = pd.read_csv('./data/train/ngrams/notes_1grams.csv', low_memory=False, chunksize = 10000, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments_keywords_unigrams = ngrams_keywords(1, departments_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_function('./data/train/ngrams/notes_1grams_DEP.csv', 'DEP', notes_ngrams, departments_keywords_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_ngrams = pd.read_csv('./data/train/ngrams/notes_2grams.csv', low_memory=False, chunksize = 10000, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments_keywords_2grams = ngrams_keywords(2, departments_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_function('./data/train/ngrams/notes_2grams_DEP.csv', 'DEP', notes_ngrams, departments_keywords_2grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_ngrams = pd.read_csv('./data/train/ngrams/notes_3grams.csv', low_memory=False, chunksize = 10000, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments_keywords_3grams = ngrams_keywords(3, departments_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_function('./data/train/ngrams/notes_3grams_DEP.csv', 'DEP', notes_ngrams, departments_keywords_3grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_2grams_matched = pd.read_csv('./data/train/ngrams/notes_2grams_DEP.csv', low_memory=False, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_2grams_matched = notes_2grams_matched.drop_duplicates()\n",
    "notes_2grams_matched['words'] = notes_2grams_matched['ngrams'].str.split(' ')\n",
    "notes_2grams_matched = notes_2grams_matched.explode('words')\n",
    "\n",
    "cols = notes_2grams_matched.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "notes_2grams_matched = notes_2grams_matched[cols]\n",
    "\n",
    "notes_2grams_matched = notes_2grams_matched.rename(columns={'ngrams':'keywords'})\n",
    "    \n",
    "notes_2grams_matched.to_csv('./data/train/ngrams/notes_ngrams_DEP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>keywords</th>\n",
       "      <th>index_notes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intensive</td>\n",
       "      <td>intensive care</td>\n",
       "      <td>1</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>care</td>\n",
       "      <td>intensive care</td>\n",
       "      <td>1</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intensive</td>\n",
       "      <td>intensive care</td>\n",
       "      <td>3</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>care</td>\n",
       "      <td>intensive care</td>\n",
       "      <td>3</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>operating</td>\n",
       "      <td>operating room</td>\n",
       "      <td>5</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39563</th>\n",
       "      <td>control</td>\n",
       "      <td>infection control</td>\n",
       "      <td>2078792</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39564</th>\n",
       "      <td>critical</td>\n",
       "      <td>critical care</td>\n",
       "      <td>2080809</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39564</th>\n",
       "      <td>care</td>\n",
       "      <td>critical care</td>\n",
       "      <td>2080809</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39565</th>\n",
       "      <td>intensive</td>\n",
       "      <td>intensive care</td>\n",
       "      <td>2081655</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39565</th>\n",
       "      <td>care</td>\n",
       "      <td>intensive care</td>\n",
       "      <td>2081655</td>\n",
       "      <td>DEP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78754 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words           keywords  index_notes label\n",
       "0      intensive     intensive care            1   DEP\n",
       "0           care     intensive care            1   DEP\n",
       "1      intensive     intensive care            3   DEP\n",
       "1           care     intensive care            3   DEP\n",
       "2      operating     operating room            5   DEP\n",
       "...          ...                ...          ...   ...\n",
       "39563    control  infection control      2078792   DEP\n",
       "39564   critical      critical care      2080809   DEP\n",
       "39564       care      critical care      2080809   DEP\n",
       "39565  intensive     intensive care      2081655   DEP\n",
       "39565       care     intensive care      2081655   DEP\n",
       "\n",
       "[78754 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_2grams_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_path = './data/train/ngrams/notes_ngrams_DEP.csv'\n",
    "\n",
    "# try:\n",
    "#     os.remove(file_path)\n",
    "# except OSError:\n",
    "#     pass\n",
    "\n",
    "# for subset in notes_2grams_matched:\n",
    "#     subset = subset.drop_duplicates()\n",
    "#     subset['words'] = subset['ngrams'].str.split(' ')\n",
    "#     subset = subset.explode('words')\n",
    "\n",
    "#     cols = subset.columns.tolist()\n",
    "#     cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "#     subset = subset[cols]\n",
    "\n",
    "#     subset = subset.rename(columns={'ngrams':'keywords'})\n",
    "\n",
    "#     if not os.path.isfile(file_path):\n",
    "#         subset.to_csv(file_path, index=False)\n",
    "#     else:\n",
    "#         subset.to_csv(file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - make knodle matrices\n",
    "# - preprocess test data\n",
    "# - alles in knodle reinnudeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Knodle Matrices</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
