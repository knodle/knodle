{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Police Killing Dataset: Data Preprocessing using RegEx as rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to find names of people killed by the police in a corpus of newspaper articles. The corpus was created by Katherine A. Keith et al. (2017) for a similar task using distant supervision. This dataset contains mentions of people (based on keywords related to “killing” or “police”) who might have been killed by the police. The dataset (the HTML documents scraped in 2016 themselves as well as the already sentence-segmented data) are available on the [project’s website](http://slanglab.cs.umass.edu/PoliceKillingsExtraction/) and on [MinIO]( https://knodle.dm.univie.ac.at/minio/knodle/datasets/police_killing/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a train and a test dataset, both of them containing dictionaries with the following keys:\n",
    "\n",
    "-\tdocid: unique identifiers of every mention of a person possible killed by the police\n",
    "-\tname: the normalized name of the person\n",
    "-\tdownloadtime: time the document was downloaded\n",
    "-\tnames_org: the original name of the person mentioned in the document\n",
    "-\tsentnames: other names in the mention (not of the person possibly killed by the police)\n",
    "-\tsent_alter: the mention, name of the person possible killed by the policed replaced by “TARGET”, any other names replaced by “POLICE”\n",
    "-\tplabel: for the training data possibly erroneous labels obtained using weak supervision and gold labels for the test data – in this project, only the labels of the test data will be used\n",
    "-\tsent_org: the original mention\n",
    "\n",
    "\n",
    "Compared to the second approach that we try for solving this problem (using a Knowledge Base for labelling, as demonstrated in the [Data Preprocessing with Knowledge Base Tutorial](https://github.com/knodle/knodle/blob/feature/%23299_police_killing_dataset/examples/data_preprocessing/police_killing/preprocessing_with_kb.ipynb), we use RegEx as rules in this tutorial. The RegEx should cover all possible ways a sentence can express that a person \"TARGET\" was killed by the police (using different words for killing and police as well as active and passive constructions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:**\n",
    "\n",
    "Keith, Kathrine A. et al. (2017): Identifying civilians killed by police with distantly supervised entity-event extraction. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. doi: [10.18653/v1/D17-1163](https://aclanthology.org/D17-1163/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from joblib import dump\n",
    "from minio import Minio\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import get_mapping_rules_labels_t\n",
    "# I need to import it like this for now, but I think after merging it with develop it should work with\n",
    "# from examples.data_preprocessing.utils import get_mapping_rules_labels_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "First of all, the file names for the output at the end of this notebook are defined. After that, the raw data can be downloaded from MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../data_from_minio/police_killing'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the files names\n",
    "Z_MATRIX_TRAIN = \"train_rule_matches_z.lib\"\n",
    "Z_MATRIX_DEV = \"dev_rule_matches_z.lib\"\n",
    "Z_MATRIX_TEST = \"test_rule_matches_z.lib\"\n",
    "\n",
    "T_MATRIX_TRAIN = \"mapping_rules_labels_t.lib\"\n",
    "\n",
    "TRAIN_SAMPLES_OUTPUT = \"df_train.lib\"\n",
    "DEV_SAMPLES_OUTPUT = \"df_dev.lib\"\n",
    "TEST_SAMPLES_OUTPUT = \"df_test.lib\"\n",
    "\n",
    "# file names for .csv files\n",
    "TRAIN_SAMPLES_CSV = \"df_train.csv\"\n",
    "DEV_SAMPLES_CSV = \"df_dev.csv\"\n",
    "TEST_SAMPLES_CSV = \"df_test.csv\"\n",
    "\n",
    "# define the path to the folder where the data will be stored\n",
    "data_path = \"../../../data_from_minio/police_killing\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.path.join(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the Train data**\n",
    "\n",
    "We read the downloaded data and convert it to a Pandas Dataframe. For now, we take only the samples for the train data and the samples as well as the labels for the test data. In the end, we will also need the name of the person in case it turns out they were killed by the police. However, in this step their name should be replaced by the TARGET symbol. Therefore, we only take the values for the \"sent_alter\" key and rename them to \"samples\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "client = Minio(\"knodle.cc\", secure=False)\n",
    "files = [\n",
    "    \"train.json\", \"test.json\"\n",
    "]\n",
    "for file in tqdm(files):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/police_killing/\", file),\n",
    "        file_path=os.path.join(data_path, file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data_path: str) -> pd.DataFrame:\n",
    "    with open(os.path.join(data_path, \"train.json\"), 'r') as data:\n",
    "        train_data = [json.loads(line) for line in data]\n",
    "    df_train_sent_alter = pd.DataFrame(train_data, columns = [\"sent_alter\"]).rename(columns={\"sent_alter\": \"sample\"})\n",
    "    return df_train_sent_alter\n",
    "\n",
    "df_train = get_train_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two years earlier , Officer TARGET was killed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police Chief PERSON said Randolph was found sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the latest incident , Chief Superintendent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chief TARGET of Penn Township police entered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man was was fatally shot by a police officer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample\n",
       "0  Two years earlier , Officer TARGET was killed ...\n",
       "1  Police Chief PERSON said Randolph was found sh...\n",
       "2  In the latest incident , Chief Superintendent ...\n",
       "3  Chief TARGET of Penn Township police entered t...\n",
       "4  A man was was fatally shot by a police officer..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the Dev and Test Data**\n",
    "\n",
    "Since the [SLANG Lab](http://slanglab.cs.umass.edu/PoliceKillingsExtraction/) provides only train and test data, but no development data, the part of the test data will be used as a development set. The samples for the development data will be selected randomly to avoid imbalances of positive and negative samples in dev and test data.\n",
    "\n",
    "The parameter *used_as_dev* reflects the amount of the gold data that should be used for development instead of testing. It is set to 30% for now, but can be changed depending on the task definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30% of the test data will be used for develoment.\n"
     ]
    }
   ],
   "source": [
    "used_as_dev = 30\n",
    "print(f\"{used_as_dev}% of the test data will be used for develoment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_test_data(data_path: str) -> Union[pd.DataFrame, pd.DataFrame]:\n",
    "    with open(os.path.join(data_path, \"test.json\"), 'r') as data:\n",
    "        dev_test_data = [json.loads(line) for line in data]\n",
    "    dev_test_sent_alter = pd.DataFrame(dev_test_data, columns = [\"sent_alter\", \"plabel\"]).rename(columns={\"sent_alter\": \"sample\", \"plabel\": \"label\"})\n",
    "    df_dev = dev_test_sent_alter.sample(n = int(round((dev_test_sent_alter.shape[0]/100)*used_as_dev))).reset_index(drop = True)\n",
    "    df_test = dev_test_sent_alter.drop(df_dev.index).reset_index(drop = True)\n",
    "    return df_dev, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev, df_test = get_dev_test_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A demonstrator confronts police officers durin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A jury of 11 white people and one black man is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Officers TARGET and PERSON were placed on modi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who Killed JonBenet ? \" starring PERSON as Jon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UPDATE 2 : The officer involved in the shootin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  label\n",
       "0  A demonstrator confronts police officers durin...      1\n",
       "1  A jury of 11 white people and one black man is...      0\n",
       "2  Officers TARGET and PERSON were placed on modi...      0\n",
       "3  Who Killed JonBenet ? \" starring PERSON as Jon...      0\n",
       "4  UPDATE 2 : The officer involved in the shootin...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ ] TARGET / Chicago Tribune Lake County Major...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Round Lake police shooting Round Lake police s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERSON shooting PERSON shooting TARGET / Chica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scene of Round Lake police shooting Scene of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>involved shooting TARGET / Chicago Tribune The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  label\n",
       "0  [ ] TARGET / Chicago Tribune Lake County Major...      0\n",
       "1  Round Lake police shooting Round Lake police s...      0\n",
       "2  PERSON shooting PERSON shooting TARGET / Chica...      0\n",
       "3  Scene of Round Lake police shooting Scene of R...      0\n",
       "4  involved shooting TARGET / Chicago Tribune The...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "Train data: 132833\n",
      "Development data: 20678\n",
      "Test data: 48247\n"
     ]
    }
   ],
   "source": [
    "# Count of samples\n",
    "\n",
    "print(f\"Number of samples:\")\n",
    "print(f\"Train data: {df_train.shape[0]}\")\n",
    "print(f\"Development data: {df_dev.shape[0]}\")\n",
    "print(f\"Test data: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the develoment data, 4377 (21.167424315697843%) instances are positive and 16301 instances (78.83257568430216%) are negative.\n",
      "In the test data, 8878 (18.40114411258731%) instances are positive and 39369 instances (81.5988558874127%) are negative.\n"
     ]
    }
   ],
   "source": [
    "# Positive and negative instances in dev and test data\n",
    "positive_dev = df_dev.groupby(\"label\").count()[\"sample\"][1]\n",
    "negative_dev = df_dev.groupby(\"label\").count()[\"sample\"][0]\n",
    "positive_test = df_test.groupby(\"label\").count()[\"sample\"][1]\n",
    "negative_test = df_test.groupby(\"label\").count()[\"sample\"][0]\n",
    "print(f\"In the develoment data, {positive_dev} ({(100/df_dev.shape[0])*positive_dev}%) instances are positive and {negative_dev} instances ({(100/df_dev.shape[0])*negative_dev}%) are negative.\")\n",
    "print(f\"In the test data, {positive_test} ({(100/df_test.shape[0])*positive_test}%) instances are positive and {negative_test} instances ({(100/df_test.shape[0])*negative_test}%) are negative.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Classes\n",
    "\n",
    "Our task is to find out whether a sentence describes the killing of a person by the police or does not. That means, it is a binary classification task with two output classes. The number of classes is defined with the *num_classes* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These word lists are mainly based on the lists of Keith et al. (2017, p. 11). However, here they are split into several different lists to create more precise RegEx. A rule must contain a police word, a killing word and in case the killing word is a shooting word, also a fatality word (due to the fact that just because someone is shot it does not necessarily mean they die). The different constructions make sure the words do not just appear in a random order in a senctence, but in a way the sentence can actually mean that the TARGET was killed by the police."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a dictionary with all the rules and their corresponding rule IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICE_WORDS = ['police', 'officer', 'officers', 'cop', 'cops', 'detective', 'sheriff', 'policeman', 'policemen',\n",
    "                'constable', 'patrolman', 'sergeant', 'detectives', 'patrolmen', 'policewoman', 'constables',\n",
    "                'trooper', 'troopers', 'sergeants', 'lieutenant', 'deputies', 'deputy']\n",
    "\n",
    "KILLING_WORDS = ['shot', 'shoots', 'shoot', 'shooting', 'shots', 'killed', 'kill', 'kills', 'killing', 'murder', 'murders', 'fires', 'fired', 'hit', 'murdered']\n",
    "\n",
    "SHOOTING_WORDS = ['shot', 'shoots', 'shoot', 'shooting', 'shots']\n",
    "\n",
    "FATALITY_WORDS = ['fatal', 'fatally', 'died', 'killed', 'killing', 'dead', 'deadly', 'homicide', 'homicides', 'death']\n",
    "\n",
    "\n",
    "def create_rules() -> Dict:\n",
    "    \n",
    "    rule2rule_id = {}\n",
    "    rule_id = 0\n",
    "    \n",
    "    for police_word in POLICE_WORDS: \n",
    "        \n",
    "        for killing_word in KILLING_WORDS:\n",
    "            if killing_word not in SHOOTING_WORDS:\n",
    "                r1 = f\"{police_word}.*{killing_word}.*target\"\n",
    "                rule2rule_id[r1] = rule_id\n",
    "                rule_id += 1\n",
    "                r2 = f\"target.*{killing_word}.*{police_word}\"\n",
    "                rule2rule_id[r2] = rule_id\n",
    "                rule_id += 1\n",
    "                r3 = f\"{killing_word}.*{police_word}.*target\"\n",
    "                rule2rule_id[r3] = rule_id\n",
    "                rule_id += 1\n",
    "            \n",
    "            else:\n",
    "                for fatality_word in FATALITY_WORDS:\n",
    "                    r4 = f\"{police_word}.*{killing_word}.*target.*{fatality_word}\"\n",
    "                    rule2rule_id[r4] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r5 = f\"{police_word}.*{fatality_word}.*{killing_word}.*target\"\n",
    "                    rule2rule_id[r5] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r6 = f\"{police_word}.*{killing_word}.*{fatality_word}.*target\"\n",
    "                    rule2rule_id[r6] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r7 = f\"{fatality_word}.*{killing_word}.*{police_word}.*target\"\n",
    "                    rule2rule_id[r7] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r8 = f\"{fatality_word}.*{killing_word}.*target.*{police_word}\"\n",
    "                    rule2rule_id[r8] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r9 = f\"target.*{police_word}.*{killing_word}.*{fatality_word}\"\n",
    "                    rule2rule_id[r9] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r10 = f\"target.*{fatality_word}.*{killing_word}.*{police_word}\"\n",
    "                    rule2rule_id[r10] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r11 = f\"target.*{killing_word}.*{fatality_word}.*{police_word}\"\n",
    "                    rule2rule_id[r11] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r12 = f\"target.*{killing_word}.*{police_word}.*{fatality_word}\"\n",
    "                    rule2rule_id[r12] = rule_id\n",
    "                    rule_id += 1\n",
    "                    r13 = f\"target.*{police_word}.*{fatality_word}.*{killing_word}\"\n",
    "                    rule2rule_id[r13] = rule_id\n",
    "                    rule_id += 1 \n",
    "                    \n",
    "                        \n",
    "    return rule2rule_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule2rule_id = create_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11660 rules.\n",
      "\n",
      "The first rules of the rule2rule_id dictionary look like this:\n",
      "{'police.*shot.*target.*fatal': 0, 'police.*fatal.*shot.*target': 1, 'police.*shot.*fatal.*target': 2, 'fatal.*shot.*police.*target': 3, 'fatal.*shot.*target.*police': 4, 'target.*police.*shot.*fatal': 5}\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(rule2rule_id)} rules.\")\n",
    "print(\"\\nThe first rules of the rule2rule_id dictionary look like this:\")\n",
    "print(dict(islice(rule2rule_id.items(), 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we create a dictionary assigning all rules to their label. There are only two classes (someone was killed by the police or was not killed by the police). Since there are no rules indicating that someone was **not** killed by the police, all rules indicate the positive class 1. Therefore, all values of the rule2label dictionary, containing the rule IDs as keys, can be set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule2label = {rule_id: 1 for rule_id in rule2rule_id.values()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, a dictionary mapping the labels to their ID as well as a dictionary mapping the ID to the corresponding label are required for the further preprocessing. As there are only two classes, this can be done manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2label_id ={\"negative\":0, \"positive\":1}\n",
    "label_id2label = {0: \"negative\", 1: \"positive\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the T matrix (rules x classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of the T matrix are the rules and the columns the classes. The T matrix is one-hot encoded. (1 for a rule and its corresponding class.) It will be imported from the data_preprocessing folder of Knodle examples, since the same function can be used in several preprocessing tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_rules_labels_t = get_mapping_rules_labels_t(rule2label, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Z matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train data. \n",
    "*(Fastest solution we could find, but takes still quite long.)*\n",
    "\n",
    "We start by creating a list of dictionaries (one for each sample, later they will be the rows in the dataframe). They contain the sample itself as well as list of the matching rules and the corresponding rule IDs. In the first step, the lists are still empty. After that, we want to populate these empty lists. We take each rule and apply it to each sample. If it matches, the rule and the rule IDs are added to the correct dictionary. In the end, the list of dictionaries can be converted into a Pandas Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data: pd.DataFrame, rule2rule_id: Dict) -> pd.DataFrame:\n",
    "    \n",
    "    data_dicts = [{\"sample\": sample, \"rules\": [], \"enc_rules\": []} for sample in data[\"sample\"].drop_duplicates()]\n",
    "    \n",
    "    for rule, rule_id in tqdm(rule2rule_id.items()):\n",
    "        for data_dict in data_dicts:\n",
    "            sample = data_dict[\"sample\"]\n",
    "            if re.search(rule, sample.lower()):\n",
    "                data_dict[\"rules\"].append(rule)\n",
    "                data_dict[\"enc_rules\"].append(rule_id)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data_dicts)            \n",
    "    df = df.reset_index()\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11660/11660 [44:30<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(df_train, rule2rule_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Dev and Test data\n",
    "\n",
    "Just as for the train data, we need a Dataframe with a sample, its corresponding rules, and the rule IDs. Moreover, we need to add the labels and the label IDs that we obtained earlier when reading the test data. We do this by merging the new Dataframe with sample, rule, and rule encoding only with the development and test Dataframes that contain the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_test_df(rule2rule_id: Dict, data: pd.DataFrame, label_id2label: Dict) -> pd.DataFrame:\n",
    "\n",
    "    dev_test_data_without_labels = get_data(data, rule2rule_id)\n",
    "    dev_test_data = dev_test_data_without_labels.merge(data, how='inner').rename(columns={\"label\": \"enc_labels\"})\n",
    "    dev_test_data[\"labels\"] = dev_test_data['enc_labels'].map(label_id2label)\n",
    "    \n",
    "    return dev_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11660/11660 [07:19<00:00, 26.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 11660/11660 [15:37<00:00, 12.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sample</th>\n",
       "      <th>rules</th>\n",
       "      <th>enc_rules</th>\n",
       "      <th>enc_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[ ] TARGET / Chicago Tribune Lake County Major...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Round Lake police shooting Round Lake police s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PERSON shooting PERSON shooting TARGET / Chica...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Scene of Round Lake police shooting Scene of R...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>involved shooting TARGET / Chicago Tribune The...</td>\n",
       "      <td>[target.*killed.*officer, target.*kill.*officer]</td>\n",
       "      <td>[1031, 1034]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             sample  \\\n",
       "0      0  [ ] TARGET / Chicago Tribune Lake County Major...   \n",
       "1      1  Round Lake police shooting Round Lake police s...   \n",
       "2      2  PERSON shooting PERSON shooting TARGET / Chica...   \n",
       "3      3  Scene of Round Lake police shooting Scene of R...   \n",
       "4      4  involved shooting TARGET / Chicago Tribune The...   \n",
       "\n",
       "                                              rules     enc_rules  enc_labels  \\\n",
       "0                                                []            []           0   \n",
       "1                                                []            []           0   \n",
       "2                                                []            []           0   \n",
       "3                                                []            []           0   \n",
       "4  [target.*killed.*officer, target.*kill.*officer]  [1031, 1034]           0   \n",
       "\n",
       "     labels  \n",
       "0  negative  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data = get_dev_test_df(rule2rule_id, df_dev, label_id2label)\n",
    "test_data = get_dev_test_df(rule2rule_id, df_test, label_id2label)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataframes to (Sparse) Matrices\n",
    "\n",
    "The train, test, and development data that we just stored as Pandas Dataframes should now be converted into a Scipy sparse matrix. The rows of the sparse matrix are the samples and the columns are the rules (i.e., a cell is 1 if the corresponding rule matches the corresponding sample, 0 otherwise). We initialize it as an array in the correct size (samples x rules), fill it with 1s and 0s, and convert it to a sparse matrix at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule_matches_z_matrix(df: pd.DataFrame) -> sp.csr_matrix:\n",
    "\n",
    "    z_array = np.zeros((len(df[\"index\"].values), len(rule2rule_id)))\n",
    "\n",
    "    for index in tqdm(df[\"index\"]):\n",
    "        enc_rules = df.iloc[index-1]['enc_rules']\n",
    "        for enc_rule in enc_rules:\n",
    "            z_array[index][enc_rule] = 1\n",
    "\n",
    "    rule_matches_z_matrix_sparse = sp.csr_matrix(z_array)\n",
    "\n",
    "    return rule_matches_z_matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 132680/132680 [00:17<00:00, 7587.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 20678/20678 [00:04<00:00, 5037.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 48247/48247 [00:07<00:00, 6835.40it/s]\n"
     ]
    }
   ],
   "source": [
    "train_rule_matches_z = get_rule_matches_z_matrix(train_data)\n",
    "dev_rule_matches_z = get_rule_matches_z_matrix(dev_data)\n",
    "test_rule_matches_z = get_rule_matches_z_matrix(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../data_from_minio/police_killing\\\\processed_regex\\\\test_rule_matches_z.lib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(os.path.join(data_path, \"processed_regex\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dump(sp.csr_matrix(mapping_rules_labels_t), os.path.join(data_path, \"processed_regex\", T_MATRIX_TRAIN))\n",
    "\n",
    "dump(train_data[\"sample\"], os.path.join(data_path, \"processed_regex\", TRAIN_SAMPLES_OUTPUT))\n",
    "train_data[\"sample\"].to_csv(os.path.join(data_path, \"processed_regex\", TRAIN_SAMPLES_CSV), header=True)\n",
    "dump(train_rule_matches_z, os.path.join(data_path, \"processed_regex\", Z_MATRIX_TRAIN))\n",
    "\n",
    "dump(dev_data[[\"sample\", \"labels\", \"enc_labels\"]], os.path.join(data_path, \"processed_regex\", DEV_SAMPLES_OUTPUT))\n",
    "dev_data[[\"sample\", \"labels\", \"enc_labels\"]].to_csv(os.path.join(data_path, \"processed_regex\", DEV_SAMPLES_CSV), header=True)\n",
    "dump(dev_rule_matches_z, os.path.join(data_path, \"processed_regex\", Z_MATRIX_DEV))\n",
    "\n",
    "dump(test_data[[\"sample\", \"labels\", \"enc_labels\"]], os.path.join(data_path, \"processed_regex\", TEST_SAMPLES_OUTPUT))\n",
    "test_data[[\"sample\", \"labels\", \"enc_labels\"]].to_csv(os.path.join(data_path, \"processed_regex\", TEST_SAMPLES_CSV), header=True)\n",
    "dump(test_rule_matches_z, os.path.join(data_path, \"processed_regex\", Z_MATRIX_TEST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Accuracy\n",
    "\n",
    "For the rule accuracy, we will compare the weak labels of the test data to the gold labels to check how reliable the rules are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 48247/48247 [00:07<00:00, 6467.27it/s]\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "matched_instances = test_data[\"enc_rules\"].str.len() != 0\n",
    "\n",
    "for row in tqdm(range(test_data.shape[0])):\n",
    "    if test_data.loc[row][\"enc_labels\"] == 1: # the true label is 1\n",
    "        if matched_instances[row]: # the predicted label is 1\n",
    "            true_positive += 1\n",
    "        else: # the predicted label is 0\n",
    "            false_negative += 1\n",
    "    else: # the true label is 0\n",
    "        if matched_instances[row]: # the predicted label is 1\n",
    "            false_positive += 1\n",
    "        else: # the predicted label is 0\n",
    "            true_negative += 1\n",
    "            \n",
    "positive_samples = test_data[test_data.enc_labels == 1].shape[0]\n",
    "negative_samples = test_data[test_data.enc_labels == 0].shape[0]\n",
    "            \n",
    "true_positive_percent = (100 / positive_samples) * true_positive\n",
    "true_negative_percent = (100 / negative_samples) * true_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 48247 samples in the test_data, 8878 samples are positive and 39369 are negative.\n",
      "\n",
      "By using only the rules to obtain weak labels, 62.07479161973417% of all positive samples are matched by a rule and therefore labeled as positive. 56.5673499453885% of all negative samples are correctly classified as negative. (Which means that 43.4326500546115% of all negative instances are covered by a rule\n",
      "\n",
      "True positives: 5511 \n",
      "True negatives: 22270 \n",
      "False positives: 17099 \n",
      "False negatives: 3367\n"
     ]
    }
   ],
   "source": [
    "print(f\"Out of {test_data.shape[0]} samples in the test_data, {positive_samples} samples are positive and {negative_samples} are negative.\\n\")\n",
    "print(f\"By using only the rules to obtain weak labels, {true_positive_percent}% of all positive samples are matched by a rule and therefore labeled as positive. {true_negative_percent}% of all negative samples are correctly classified as negative. (Which means that {100 - true_negative_percent}% of all negative instances are covered by a rule\\n\")\n",
    "print(f\"True positives: {true_positive} \\nTrue negatives: {true_negative} \\nFalse positives: {false_positive} \\nFalse negatives: {false_negative}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The false negatives can be saved in a separate CSV in order to look at them and and get an impression why they were not matched by any rule..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 48247/48247 [00:16<00:00, 2990.19it/s]\n"
     ]
    }
   ],
   "source": [
    "false_negative_list = []\n",
    "for row in tqdm(range(test_data.shape[0])):\n",
    "    if test_data.loc[row][\"enc_labels\"] == 1: # the true label is 1\n",
    "        if matched_instances[row] == False: # the predicted label is 1\n",
    "             false_negative_list.append(row)\n",
    "                \n",
    "false_negative_df = test_data.iloc[false_negative_list]\n",
    "false_negative_df[[\"samples\"]].to_csv(os.path.join(data_path, \"false_negatives.csv\"), header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish\n",
    "\n",
    "Compared to the names of the Fatal Encounters database used in the [alternative tutorial](https://github.com/knodle/knodle/blob/feature/%23299_police_killing_dataset/examples/data_preprocessing/police_killing/preprocessing_with_kb.ipynb), the rule accuracy when using RegEx is much lower. They only detect around 62% of all positive instances. Different denoising methods, which will be applied in the next step, should now further improve the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
